# 患者レベル予測 {#PatientLevelPrediction}

*著者: Peter Rijnbeek & Jenna Reps*

\index{患者レベル予測}

臨床意思決定は、利用可能な患者の病歴と現在の臨床ガイドラインに基づいて診断や治療経路を推測するという複雑な作業です。臨床予測モデルは、この意思決定プロセスを支援するために開発され、幅広い専門分野で臨床実践に使用されています。これらのモデルは、例えば、人口統計情報、病歴、および治療歴など、患者の特性の組み合わせに基づいて診断アウトカムや予後アウトカムを予測します。 \index{臨床意思決定} \index{診断アウトカム} \index{予後アウトカム}

過去10年間で、臨床予測モデルを説明する出版物の数が大幅に増加しました。現在使用されているほとんどのモデルは、小さなデータセットを使用して推定されており、患者特性の限られたセットのみを考慮しています。この低いサンプルサイズ、従って低い統計的検出力は、データアナリストに強いモデリング仮定を行わせます。限られた患者特性の選択は、手元にある専門知識に強く導かれています。これは、患者が膨大なデジタルトレイルを生成する現代医学の現実とは対照的です。現在、ヘルスケアは電子健康記録（EHR）に保存された膨大な患者特有の情報を生成しています。これには、診断、投薬、検査アウトカムの形での構造化データ、および臨床記述に含まれる非構造化データが含まれます。患者の完全なEHRから得られる大量のデータを活用することで、どれだけの予測精度が向上するかは未知です。 \index{予測モデル}

大規模データセットの解析に対する機械学習の進歩により、この種類のデータに対する患者レベルの予測の適用に対する関心が高まっています。しかし、患者レベルの予測に関する多くの発表された取り組みがモデル開発ガイドラインに従っておらず、広範な外部検証を行わない、またはモデルの詳細が不十分であるため、独立した研究者がモデルを再現し外部検証を行うことが難しくなっています。これにより、モデルの予測性能を公正に評価することが難しくなり、モデルが臨床実践で適切に使用される可能性が低くなります。標準を向上させるために、いくつかの論文が予測モデルの開発および報告のベストプラクティスに関するガイドラインを詳述しています。例えば、個々の予後または診断のための多変数予測モデルの透明な報告（TRIPOD）ステートメント [^patientlevelprediction-1] は、予測モデルの開発と検証を報告するための明確な推奨事項を提供し、透明性に関連するいくつかの懸念に対処しています。 \index{機械学習} \index{TRIPOD}

[^patientlevelprediction-1]: <https://www.equator-network.org/reporting-guidelines/tripod-statement/>

OHDSIのおかげで、大規模、患者特異的予測モデリングが現実のものとなり、共通データモデル（CDM）が前例のない規模での均一で透明な分析を可能にしました。CDMに標準化された拡大するデータベースネットワークは、さまざまなヘルスケア環境でのモデルの外部検証をグローバルに可能にします。私たちは、これがケアの質の向上が最も必要とされる大規模な患者コミュニティに直ちに貢献できる機会を提供すると信じています。このようなモデルは、真に個別化された医療を支援し、患者の治療アウトカムの劇的な向上を目指します。

この章では、OHDSIの標準化された患者レベル予測のフレームワーク [@reps2018] を説明し、開発と検証のための確立されたベストプラクティスを実装する [PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) R パッケージについて説明します。まず、患者レベルの予測の開発と評価のための必要な理論を提供し、実装された機械学習アルゴリズムの概要を高レベルで説明します。次に、予測課題の例を示し、その定義とATLASやカスタムRコードを使用した実装のステップバイステップガイダンスを提供します。最後に、研究アウトカムの普及のためのShinyアプリケーションの使用について説明します。

## 予測課題

図 \@ref(fig:figure1) は私たちが取り組む予測課題を示しています。リスク集団の中で、定義された時点（t = 0）でどの患者がリスク期間中にあるアウトカムを経験するかを予測することを目指します。予測は、その時点までの観察期間中の患者の情報のみを使用して行います。

\begin{figure}
\includegraphics[width=1\linewidth]{images/PatientLevelPrediction/Figure1} \caption{予測課題}(\#fig:figure1)
\end{figure}

表 \@ref(tab:plpDesign) に示すように、予測課題を定義するには、ターゲットコホートによってt=0を定義し、アウトカムコホートによって予測したいアウトカムを定義し、リスク期間を定義する必要があります。標準的な予測質問は次のように定義されます： \index{ターゲットコホート} \index{アウトカムコホート} \index{リスク期間}

> *[ターゲットコホートの定義]*の中で、*[リスク期間]*内に*[アウトカムコホートの定義]*を持つようになるのは誰ですか？

さらに、開発したいモデルの設計選択肢を検討し、内部および外部検証を行うための観察データセットを決定する必要があります。

| 選択肢 | 説明 |
|:---|:---|
| ターゲットコホート | 予測したい人物のコホートをどのように定義しますか？ |
| アウトカムコホート | 予測したいアウトカムをどのように定義しますか？ |
| リスク期間 | t=0に対してどの時間ウィンドウで予測を行いますか？ |
| モデル | どのアルゴリズムを使用し、どの潜在的な予測変数を含めますか？ |

: (#tab:plpDesign) 予測設計における主要な設計選択肢

この概念的フレームワークは、すべての種類の予測課題に適用されます。例えば：

-   疾病の発症と進行
    -   **構造**: *[病気]*と新たに診断された患者の中で、*[診断からの時間枠内]*に*[別の病気または合併症]*を発症するのは誰ですか？
    -   **例**: 心房細動と新たに診断された患者の中で、次の3年の間に虚血性脳卒中を発症するのは誰ですか？
-   治療選択
    -   **構造**: *[適応された疾患]*を持ち*、*[治療1]*または*[治療2]*で治療された患者の中で、*[治療1]\*で治療されたのは誰ですか？
    -   **例**: ワルファリンまたはリバロキサバンを服用した心房細動患者の中で、ワルファリンを服用する患者は誰ですか？（例えば傾向スコアモデルとして）
-   治療反応
    -   **構造**: *[治療]*の新規使用者の中で、*[時間枠内]*に*[ある効果]*を経験するのは誰ですか？
    -   **例**: メトホルミンを開始した糖尿病患者のうち、3年間メトホルミンを継続するのは誰ですか？
-   治療安全性
    -   **構造**: *[治療]*の新規使用者の中で、*[時間枠内]*に*[副作用]*を経験するのは誰ですか？
    -   **例**: ワルファリンの新規使用者の中で、1年以内に消化管出血を経験するのは誰ですか？
-   治療遵守
    -   **構造**: *[治療]*の新規使用者の中で、*[時間枠]*で*[遵守指標]*を達成するのは誰ですか？
    -   **例**: メトホルミンを開始した糖尿病患者のうち、1年後に80%以上の日数カバー率を達成するのは誰ですか？

## データ抽出

予測モデルを作成する際には、監督学習として知られるプロセスを使用します。これは、機械学習の一形態で、目標変数と結び付いたラベル付きデータから、共変量とアウトカムステータスの関係を推測する方法です\index{supervised learning(監督学習)}。したがって、CDMからターゲットコホートに属する個人の共変量を抽出する方法、およびそのアウトカムステータスを取得する方法が必要です。

**共変量**（"予測因子"、"特徴"、または"独立変数"とも呼ばれる）は、患者の特性を説明します\index{共変量}。共変量には、年齢、性別、特定のコンディションの存在、患者記録内の曝露コードなどが含まれます。共変量は一般的に、[FeatureExtraction](https://ohdsi.github.io/FeatureExtraction/)パッケージを使用して構築され、詳細は第 \@ref(Characterization) 章で説明しています。予測のためには、個人がターゲットコホートに入る日付（本書ではこれを基準日と呼びます）の前および当日のデータのみ使用できます。\index{基準日}

また、リスク期間中の全ての患者の**アウトカムステータス**（"ラベル"または"クラス"とも呼ばれる）も取得する必要があります。リスク期間中にアウトカムが発生した場合、アウトカムステータスは「陽性」と定義されます。\index{アウトカムステータス} \index{ラベル} \index{クラス}

### データ抽出の例

表 \@ref(tab:plpExampleCohorts) は、2つのコホートが含まれたCOHORTテーブルの例を示しています。コホート定義IDが1のコホートはターゲットコホート（例：「最近心房細動と診断された人々」）です。コホート定義IDが2は、アウトカムコホートを定義します（例：「脳卒中」）。

| COHORT_DEFINITION_ID | SUBJECT_ID | COHORT_START_DATE |
|:--------------------:|:----------:|:-----------------:|
|          1           |     1      |    2000-06-01     |
|          1           |     2      |    2001-06-01     |
|          2           |     2      |    2001-07-01     |

: (#tab:plpExampleCohorts) 例示的なCOHORTテーブル。簡潔のためにCOHORT_END_DATEは省略しています。

表 \@ref(tab:plpExampleConditions) は、例示的なCONDITION_OCCURRENCEテーブルを示しています。Concept ID [320128](http://athena.ohdsi.org/search-terms/terms/320128) は「本態性高血圧」に該当します。

| PERSON_ID | CONDITION_CONCEPT_ID | CONDITION_START_DATE |
|:---------:|:--------------------:|:--------------------:|
|     1     |        320128        |      2000-10-01      |
|     2     |        320128        |      2001-05-01      |

: (#tab:plpExampleConditions) 例示的なCONDITION_OCCURRENCEテーブル。簡潔のため、3つの列のみ表示しています。

この例示的なデータに基づき、時間のリスクが基準日（ターゲットコホートの開始日）から1年間と仮定すると、共変量とアウトカムステータスを構築できます。「前年の本態性高血圧」を示す共変量は、個人ID 1に対して0（非存在）（状態が基準日後に発生）と、個人ID 2に対して1（存在）を持ちます。同様に、アウトカムステータスは個人ID 1に対して0（この人はアウトカムコホートにエントリがない）、個人ID 2に対して1（基準日から1年以内にアウトカムが発生）となります。

### 否定 vs 欠損

観察医療データは、値が否定的か欠損しているかを示すことは滅多にありません。前の例では、単にID 1の人が基準日前に本態性高血圧の発生がなかったことを観察しました。これは、その時点で状態が存在しなかった（否定的）または記録されなかった（欠損）可能性があります。機械学習アルゴリズムは否定的と欠損の区別がつかず、利用可能なデータから予測価値を評価することを理解しておくことが重要です。\index{欠損データ}

## モデルの適合 {#modelFitting}

予測モデルの適合を行う際には、ラベル付きの例から共変量と観測されたアウトカム状態の関係を学習しようとしています。例えば、共変量が2つしかない場合、収縮期血圧と拡張期血圧だとすると、各患者を2次元空間のプロットとして表現できます（図 \@ref(fig:decisionBoundary) を参照）。この図では、データポイントの形が患者のアウトカム状態（例：脳卒中）に対応しています。

指導付き学習モデルは、2つのアウトカムクラスを最適に分離する決定境界を見つけようとします。異なる指導付き学習技術は異なる決定境界を導き、しばしば決定境界の複雑さに影響を与えるハイパーパラメータが存在します。 \index{decision boundary}

\begin{figure}

{\centering \includegraphics[width=0.8\linewidth]{images/PatientLevelPrediction/decisionBoundary} 

}

\caption{決定境界}(\#fig:decisionBoundary)
\end{figure}

図 \@ref(fig:decisionBoundary) では、三つの異なる決定境界を見ることができます。境界は新しいデータポイントのアウトカム状態を推測するために使用されます。新しいデータポイントが陰影部分に落ちると、モデルは「アウトカムがある」と予測し、そうでない場合は「アウトカムなし」と予測します。理想的には、決定境界は2つのクラスを完全に分離するべきです。しかし、あまりにも複雑なモデルはデータに「過適合」するリスクがあります。これは、未見のデータに対するモデルの一般化可能性を悪化させる可能性があります。例えば、データにノイズが含まれている場合（誤ってラベル付けされたデータポイントや誤った位置に配置されたデータポイントなど）、そのノイズにモデルを適合させたくないでしょう。したがって、トレーニングデータで完全に区別しないが、「真の」複雑さを捉える決定境界を定義することを好むかもしれません。正則化のような技術は、モデルのパフォーマンスを最大限にしながら複雑さを最小限に抑えることを目指しています。

各指導付き学習アルゴリズムは決定境界を学習する異なる方法を持っており、どのアルゴリズムがデータに最も適しているかを簡単に判断することはできません。No Free Lunch定理が述べているように、1つのアルゴリズムがすべての予測問題に対して常に他よりも優れているわけではありません。\index{no free lunch} したがって、患者レベルの予測モデルを開発する際には、複数の指導付き学習アルゴリズムをさまざまなハイパーパラメータ設定で試すことをお勧めします。

この後に示すアルゴリズムは以下から取得可能です： [PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) パッケージ

### 正則化ロジスティック回帰

LASSO（最小絶対収縮および選択オペレーター）ロジスティック回帰は、変数の線形結合を学習し、最終的にロジスティック関数がその線形結合を0から1の値にマッピングする、一般化線形モデルの家族に属します。LASSO正則化は、モデルをトレーニングする際に目的関数に基づくモデルの複雑さに基づくコストを追加します。このコストは係数の線形結合の絶対値の合計です。このモデルは、このコストを最小限に抑えることで自動的に特徴選択を行います。大規模な正則化ロジスティック回帰を行うために [Cyclops](https://ohdsi.github.io/Cyclops/) （ロジスティック、ポアソン、サバイバル分析のためのサイクリック座標降下法）パッケージを使用しています。 \index{LASSO} \index{logistic regression} \index{regularization} \index{Cyclops}

| パラメータ | 説明               | 典型的な値 |
|:-----------|:-------------------|:-----------|
| 初期分散   | 事前分布の初期分散 | 0.1        |

: (#tab:lassoParameters) 正則化ロジスティック回帰のハイパーパラメータ

分散はクロスバリデーションでのサンプル外の尤度を最大化して最適化されるため、初期分散はアウトカムとして得られるモデルの性能にはほとんど影響しません。ただし、最適値からあまりに離れた初期分散を選択すると、適合時間が長くなる可能性があります。\index{variance} \index{hyper-parameter} \index{cross-validation}

### 勾配ブースティングマシン

勾配ブースティングマシンはブースティングアンサンブル技術であり、我々の枠組みでは複数の決定木を組み合わせます。ブースティングは、繰り返し決定木を追加し、前の決定木で誤分類されたデータポイントにより多くの重みをコスト関数に追加して次の木をトレーニングします。高効率の勾配ブースティングフレームワークを実装した、CRANで利用可能なxgboost Rパッケージを使用しています。 \index{gradient boosting} \index{xgboost}

| パラメータ     | 説明                           | 典型的な値     |
|:---------------|:-------------------------------|:---------------|
| earlyStopRound | 改善がない場合の停止ラウンド数 | 25             |
| learningRate   | ブースティングの学習率         | 0.005,0.01,0.1 |
| maxDepth       | 木の最大深さ                   | 4,6,17         |
| minRows        | ノード内の最小データポイント数 | 2              |
| ntrees         | 木の数                         | 100,1000       |

: (#tab:gbmParameters) 勾配ブースティングマシンのハイパーパラメータ

### ランダムフォレスト

ランダムフォレストは複数の決定木を組み合わせるバギングアンサンブル技術です。バギングの背後にあるアイデアは、弱い分類器を使用してそれらを強い分類器に組み合わせることで過適合の可能性を減らすことです。ランダムフォレストは、各木において変数のサブセットを使用し、木間でサブセットを異ならせることでこれを実現します。Pythonのsklearnのランダムフォレスト実装を使用しています。 \index{random forest} \index{python} \index{sklearn}

| パラメータ | 説明         | 典型的な値                 |
|:-----------|:-------------|:---------------------------|
| maxDepth   | 木の最大深さ | 4,10,17                    |
| mtries     | 各木の変数数 | -1 = 総変数数の平方根,5,20 |
| ntrees     | 木の数       | 500                        |

: (#tab:randomForestParameters) ランダムフォレストのハイパーパラメータ

### K-近傍法

K-nearest neighbors (KNN) は、ある距離測定を使用して新しい未ラベルデータポイントに最も近いラベル付きデータポイントK個を見つけるアルゴリズムです。新しいデータポイントの予測は、K個の近傍ラベル付きデータポイントの中で最も多く見られるクラスになります。KNNの制限として、モデルが新しいデータに対して予測を行うためにラベル付きデータを必要とし、そのデータはデータサイト間で共有しにくい場合が多いことがあります。我々のパッケージには、OHDSIで開発された大規模なKNN分類器である [BigKnn](https://github.com/OHDSI/BigKnn) パッケージが含まれています。 \index{k-nearest neighbors} \index{bigknn}

| パラメータ | 説明   | 典型的な値 |
|:-----------|:-------|:-----------|
| k          | 近傍数 | 1000       |

: (#tab:knnParameters) K-近傍法のハイパーパラメータ

### ナイーブベイズ

ナイーブベイズアルゴリズムは、クラス変数の値が与えられた全ての特徴ペアの条件付き独立性を仮定するベイズの定理を適用します。データがクラスに属する尤もらしさとクラスの事前分布に基づいて、事後分布が得られます。ナイーブベイズにはハイパーパラメータはありません。 \index{naive bayes}

### AdaBoost

AdaBoostはブースティングアンサンブル技術です。ブースティングは、繰り返し分類器を追加し、前の分類器で誤分類されたデータポイン規定の重みをコスト関数に追加して次の分類器をトレーニングします。Pythonのsklearn AdaboostClassifier実装を使用しています。 \index{adaboost} \index{python}

| パラメータ | 説明 | 典型的な値 |
|:---|:---|:---|
| nEstimators | ブースティングが停止される最大推定器数 | 4 |
| learningRate | 学習率が各分類器の貢献をlearning_rateによって抑え込みます。learningRateとnEstimatorsの間にはトレードオフがあります | 1 |

: (#tab:adaBoostParameters) AdaBoostのハイパーパラメータ

### 決定木

決定木は、貪欲法を用いた個々のテストを使って変数空間を分割する分類器です。クラスを分離するために最も高い情報利得を持つ分割を見つけることを目指します。決定木は、大量の分割（木の深さ）を可能にすることで容易に過適合を引き起こし、しばしば正則化（例：剪定やモデルの複雑さを制限するハイパーパラメータの指定など）が必要です。Pythonのsklearn DecisionTreeClassifier実装を使用しています。 \index{decision tree} \index{python}

| パラメータ | 説明 | 典型的な値 |
|:---|:---|:---|
| classWeight | "Balance"または"None" | None |
| maxDepth | 木の最大深さ | 10 |
| minImpuritySplit | 木の成長中に早期停止するための閾値。ノードの不純物が閾値を上回る場合は分割され、そうでない場合はリーフとなります | 10\^-7 |
| minSamplesLeaf | 各リーフの最小サンプル数 | 10 |
| minSamplesSplit | 各分割の最小サンプル数 | 2 |

: (#tab:decisionTreeParameters) 決定木のハイパーパラメータ

### 多層パーセプトロン

多層パーセプトロンは、複数の層のノードを含むニューラルネットワークであり、入力を重み付けするために非線形関数を用います。最初の層は入力層、最後の層は出力層、その間に隠れ層があります。ニューラルネットワークは一般に逆伝播を使ってトレーニングされ、トレーニング入力がネットワークを前方に伝播して出力を生成し、出力とアウトカム状態の間の誤差が計算され、その誤差がネットワークを逆伝播して線形関数の重みを更新します。 \index{neural network} \index{perceptron} \index{back-propagation}

| パラメータ | 説明           | 典型的な値 |
|:-----------|:---------------|:-----------|
| alpha      | l2正則化       | 0.00001    |
| size       | 隠れノードの数 | 4          |

: (#tab:mpParameters) 多層パーセプトロンのハイパーパラメータ

### ディープラーニング

ディープラーニングは、ディープネット、畳み込みニューラルネットワーク、またはリカレントニューラルネットワークのように、多層パーセプトロンに似ていますが、予測に役立つ潜在表現を学習するための複数の隠れ層を持ちます。[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) パッケージの別の[ビネット](https://ohdsi.github.io/PatientLevelPrediction/articles/BuildingDeepLearningModels.html)で、これらのモデルとハイパーパラメータの詳細について説明しています。 \index{deep learning} \index{convolutional neural network} \index{recurrent neural networks}

### その他のアルゴリズム

患者レベルの予測フレームワークには他のアルゴリズムを追加できますが、これはこの章の範囲外です。詳細は、[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) パッケージの["Adding Custom Patient-Level Prediction Algorithms"ビネット](https://ohdsi.github.io/PatientLevelPrediction/articles/AddingCustomAlgorithms.html)をご覧ください。

## 予測モデルの評価

### 評価の種類

予測モデルの評価は、モデルの予測と観測されたアウトカムの一致度を測定することによって行うことができます。これには、アウトカムのステータスが既知のデータが必要です。 \index{予測モデルの評価}

\BeginKnitrBlock{rmdimportant}
評価には、モデルの開発に使用されたデータセットとは異なるデータセットを使用しなければなりません。そうしないと、過剰適合したモデルを好む可能性があり（セクション \@ref(modelFitting) を参照）、新しい患者には適切に機能しない可能性があります。
\EndKnitrBlock{rmdimportant}

評価の種類には、以下のものがあります：

-   **内部検証**：同じデータベースから抽出された異なるデータセットを使用してモデルを開発および評価します。
-   **外部検証**：一つのデータベースでモデルを開発し、別のデータベースで評価します。 \index{検証!内部検証} \index{検証!外部検証}

内部検証の方法には、次の2つがあります：

-   **ホールドアウトセット**アプローチ：ラベル付きデータを独立した2つのセット、トレインセットとテストセット（ホールドアウトセット）に分割します。トレインセットはモデルの学習に使用され、テストセットはモデルの評価に使用されます。患者をランダムにトレインセットとテストセットに分けるか、以下の方法を選ぶことができます：
    -   時間に基づいた分割（時間的検証）：例えば、特定の日付より前のデータで訓練し、その日付以降のデータで評価します。これにより、モデルが異なる時間帯に一般化されるかどうかを判断できます。
    -   地理的位置に基づいた分割（空間的検証）。\index{検証!時間的検証} \index{検証!空間的検証}
-   **クロスバリデーション**：データが限られている場合に有用です。データを等しいサイズに分割し、$n$にプレ設定されたセットに分割します（例：$n=10$）。各セットに対して、そのセットのデータを除いた全てのデータでモデルを訓練し、ホールドアウトセットの予測を生成します。この方法で、すべてのデータが一度はモデル構築アルゴリズムを評価するために使用されます。患者レベルの予測フレームワークでは、クロスバリデーションを使用して最適なハイパーパラメータを選択します。 \index{交差検証}

外部検証は、モデルが開発された設定外の別のデータベースに対するモデルの性能を評価することを目的としています。このモデルの移植性の尺度は重要です。なぜなら、モデルを訓練したデータベースだけでなく、他のデータベースでもモデルを適用したいからです。異なるデータベースは、異なる患者集団、異なる医療システム、および異なるデータキャプチャプロセスを表す可能性があります。大規模なデータベースセットでの予測モデルの外部検証は、モデルの受け入れと臨床実務への実装に向けて重要なステップだと考えています。

### パフォーマンス指標 {#performance}

#### 閾値測定 {.unnumbered}

予測モデルは、リスク期間中に患者がアウトカムを持つリスクに対応する0から1の間の値を各患者に割り当てます。値が0の場合、リスクは0％、値が0.5の場合、リスクは50％、値が1の場合、リスクは100％を意味します。精度、感度、特異度、陽性予測値などの一般的な指標は、リスク期間中にアウトカムを持つかどうかを分類するために使用される閾値を指定することによって計算できます。例えば、表 \@ref(tab:tabletheorytab) にあるように閾値を0.5と設定すると、患者1、3、7、および10は閾値0.5以上の予測リスクを持つため、アウトカムを持つと予測されます。他のすべての患者は0.5未満の予測リスクを持つため、アウトカムを持たないと予測されます。 \index{パフォーマンス指標} \index{精度} \index{感度} \index{特異度} \index{陽性予測値}

| 患者ID | 予測リスク | 0.5閾値での予測クラス | リスク期間中にアウトカムを持つ | タイプ |
|:--:|:--:|:--:|:--:|:--:|
| 1 | 0.8 | 1 | 1 | TP |
| 2 | 0.1 | 0 | 0 | TN |
| 3 | 0.7 | 1 | 0 | FP |
| 4 | 0 | 0 | 0 | TN |
| 5 | 0.05 | 0 | 0 | TN |
| 6 | 0.1 | 0 | 0 | TN |
| 7 | 0.9 | 1 | 1 | TP |
| 8 | 0.2 | 0 | 1 | FN |
| 9 | 0.3 | 0 | 0 | TN |
| 10 | 0.5 | 1 | 0 | FP |

: (#tab:tabletheorytab) 予測確率に対する閾値の利用例

患者が予測されたアウトカムを持ち、実際にアウトカムを持つ場合、それを真陽性（TP）と呼びます。患者が予測されたアウトカムを持っているが実際にはアウトカムを持っていない場合、それを偽陽性（FP）と呼びます。患者がアウトカムを持たないと予測され、実際にアウトカムを持っていない場合、それを真陰性（TN）と呼びます。最後に、患者がアウトカムを持たないと予測され、実際にアウトカムを持っている場合、それを偽陰性（FN）と呼びます。 \index{真陽性} \index{偽陽性} \index{真陰性} \index{偽陰性}

以下の閾値ベースの指標を計算できます：

-   精度: $(TP+TN)/(TP+TN+FP+FN)$
-   感度: $TP/(TP+FN)$
-   特異度: $TN/(TN+FP)$
-   陽性予測値: $TP/(TP+FP)$

これらの値は、閾値が下げられると増減する可能性があります。分類器の閾値を下げると、アウトカムの数を増やすことで分母を増やすことができます。以前の閾値が高すぎた場合、新しいアウトカムはすべて真陽性である可能性があり、これにより陽性予測値が増加します。以前の閾値が適切であったか低すぎた場合、さらなる閾値の低下は偽陽性を導入するため、陽性予測値が減少します。感度の場合、分母は分類器の閾値に依存しません（$TP+FN$は一定です）。このため、分類器の閾値を下げることで真陽性アウトカム数を増やし、感度を向上させる可能性があります。また、閾値を下げても感度が変わらない一方で、陽性予測値が変動することもあります。

#### 識別力 {.unnumbered}

識別力とは、リスク期間中にアウトカムを経験する患者に対して、より高いリスクを割り当てる能力のことです。受信者動作特性曲線（ROC曲線）は、全ての可能な閾値でx軸に1 - 特異度、y軸に感度をプロットすることで作成されます。ROCプロットの例は、この章の後半に図 \@ref(fig:shinyROC) で示されています。受信者動作特性曲線下の面積（AUC）は、識別力の全体的な測定値を示し、値が0.5はリスクがランダムに割り当てられることを示し、1は完璧な識別力を意味します。発表された予測モデルの多くは、AUCが0.6から0.8の範囲に収まります。 \index{AUC} \index{ROC} \index{識別力}

AUCは、リスク期間中にアウトカムを経験する患者と経験しない患者との間で予測リスク分布がどれだけ異なるかを判断する方法を提供します。AUCが高い場合、分布はほとんど重ならないのに対し、重なりが多い場合はAUCが0.5に近くなります。図 \@ref(fig:figuretheoryroctheory) に示されているようにです。

\begin{figure}
\includegraphics[width=1\linewidth]{images/PatientLevelPrediction/theory/roctheory} \caption{識別力に関連するROCプロット。2つのクラスの予測リスクの分布が類似している場合、ROCは対角線に近く、AUCは0.5に近くなります。}(\#fig:figuretheoryroctheory)
\end{figure}

非常に稀なアウトカムに対しては、AUCが高くても実際には実用的でない場合があります。なぜなら、閾値を超えるすべての陽性の背後には多くの陰性が存在し、陽性予測値が低くなる可能性があるからです。アウトカムの重大性および介入のコスト（健康リスクまたは金銭的）があるため、高い偽陽性率は望ましくないかもしれません。そのため、稀なアウトカムに対しては、適合率-再現率曲線下の面積（AUPRC）と呼ばれる別の測定値が推奨されます。AUPRCは、感度をx軸（再現率としても知られる）に、陽性予測値（適合率としても知られる）をy軸にプロットして生成される線の下の面積です。 \index{適合率-再現率曲線下の面積}

#### キャリブレーション {.unnumbered}

キャリブレーションは、モデルが正しいリスクを割り当てる能力です。例えば、モデルが100人の患者に10％のリスクを割り当てた場合、そのうち10人がリスク期間中にアウトカムを経験するべきです。同様に、モデルが100人の患者に80％のリスクを割り当てた場合、そのうち80人がリスク期間中にアウトカムを経験するべきです。キャリブレーションは、一般的に予測リスクに基づいて患者を十分位に分割し、各グループで平均予測リスクとリスク期間中にアウトカムを経験した患者の割合を計算することによって測定されます。次に、これらの10点（予測リスクをy軸、観測リスクをx軸にプロット）をプロットし、それらがx = yの線上に位置するかどうかを確認します。これがモデルが適切にキャリブレーションされていることを示します。キャリブレーションプロットの例は、この章の後半に図 \@ref(fig:shinyCal) で示されています。また、これらの点を使用して線形モデルをフィットし、切片（ゼロに近いはず）と傾き（1に近いはず）を計算します。もし、傾きが1より大きい場合、モデルは実際のリスクよりも高いリスクを割り当てており、傾きが1より小さい場合、モデルは実際のリスクよりも低いリスクを割り当てていることを意味します。非線形関係をよりよく捕捉するために、Smooth Calibration Curvesも実装しています。 \index{キャリブレーション}

## 患者レベル予測研究の設計

このセクションでは予測研究の設計方法を実演します。最初のステップは予測問題を明確に定義することです。興味深いことに、公開された多くの論文では予測問題が不十分に定義されています。例えば、インデックス日（ターゲットコホートの開始日）がどのように定義されているかが不明確です。予測問題が不十分に定義されていると、他者による外部検証や臨床実践への実装が困難になります。患者レベルの予測フレームワークでは、表 \@ref(tab:plpDesign)に定義された主要な選択肢を明示的に定義することを要求することにより、予測問題の適切な仕様を強調します。ここでは、「治療の安全性」というタイプの予測問題を例にして、このプロセスを説明します。 \index{インデックス日}

### 問題の定義

血管性浮腫はACE阻害薬のよく知られた副作用であり、ACE阻害薬のラベルに記載されている血管性浮腫の発生率は0.1％から0.7％の範囲です [@byrd_2006]。 この副作用を監視することは重要です。なぜなら、血管性浮腫は稀であるものの、生命を脅かす可能性があり、呼吸停止や死亡に至ることがあるからです [@norman_2013]。 さらに、血管性浮腫が最初に認識されないと、その原因を特定するまでに広範で費用のかかる検査が行われる可能性があります　[@norman_2013; @thompson_1993]。 アフリカ系アメリカ人患者におけるリスクの増加以外に、ACE阻害薬関連の血管性浮腫の発症に対する既知の素因はありません [@byrd_2006]。 ほとんどの反応は初めての治療の最初の週または月以内に、しばしば最初の投与から数時間以内に発生します [@circardi_2004]。 しかし、一部の症例は治療開始から数年後に発生することもあります [@mara_1996]。 リスクのある人を特定する特定の診断テストは利用できません。もしリスクのある人を特定できれば、医師は例えばACE阻害薬を別の降圧薬に切り替えるなどの対応が可能です。 \index{血管性浮腫} \index{ACE阻害薬}

患者レベル予測フレームワークを観察医療データに適用して、次の患者レベルの予測問題に取り組みます：

> 初めてACE阻害薬を開始した患者の中で、翌年に血管性浮腫を経験するのは誰か？

### 研究集団の定義

最終的な研究集団はターゲットコホートのサブセットであることが多いです。なぜなら、例えばアウトカムに依存する基準を適用したり、対象コホートのサブ集団で感度分析を行いたい場合があるからです。このため、次の質問に答える必要があります：

-   *ターゲットコホートの開始前にどの程度の観察期間が必要ですか？* この選択肢は、トレーニングデータで利用可能な患者時間や、将来モデルを適用したいデータソースで利用可能な時間に依存する可能性があります。最小観察期間が長いほど、各人のフィーチャー抽出に利用できる基礎履歴期間が長くなりますが、分析対象となる患者数は減少します。さらに、短期間や長期間のルックバック期間を選ぶには臨床的な理由があるかもしれません。私たちの例では、365日の履歴期間をルックバック期間（ウォッシュアウト期間）として使用します。

-   *患者がターゲットコホートに複数回入ることができますか？* ターゲットコホートの定義では、個人は異なる期間にコホートに複数回適格となる可能性があります。例えば、異なる病気のエピソードを持っていたり、医療製品への曝露期間が異なる場合です。コホートの定義では必ずしも患者が一度だけ入る制限を適用するわけではありませんが、特定の患者レベルの予測問題の文脈では、このような制限を課すことがあります。私たちの例では、ACE阻害薬の初回使用に基づいているため、個人はターゲットコホートに一度しか入ることができません。

-   *以前にアウトカムを経験した人をコホートに含めることができますか？* ターゲットコホートに適格となる前にアウトカムを経験した人をコホートに含めるかどうかを決める必要があります。特定の患者レベルの予測問題によっては、初回のアウトカムの発生を予測したい場合があるため、以前にアウトカムを経験した患者はリスクがないため、ターゲットコホートから除外する必要があります。他の状況では、前回エピソードの予測を希望しているため、以前のアウトカムが将来のアウトカムの予測要因になる可能性もあります。私たちの予測例では、以前に血管性浮腫を持つ人を含めないことにします。

-   *ターゲットコホート開始日に対してアウトカムを予測する期間をどう定義しますか？* この質問に答えるために、2つの決定を下す必要があります。最初に、リスク期間の開始日をターゲットコホートの開始日またはそれ以降に設定するかどうかの議論があります。開始日を遅らせる理由には、ターゲットコホート開始前に発生したアウトカムを記録に遅れて入力したケースや、アウトカムを防ぐための介入が理論上実施されるギャップを設けることが含まれます。第二に、リスク期間終了をターゲットコホートの開始日または終了日を基準とした日数オフセットとして設定します。私たちの問題では、ターゲットコホート開始後1日から365日までのリスク期間を予測します。

-   *最小リスク期間を要求しますか？* アウトカムが発生しなかったが、リスク期間終了前にデータベースを離れた患者を含めるかどうかを決める必要があります。これらの患者は私たちの観察が終わった後にアウトカムを経験する可能性があります。私たちの予測問題では、この質問に「はい」と答え、その理由で最小リスク期間を要求します。さらに、この制約がアウトカムを経験した人にも適用されるかどうかも決定する必要があります。アウトカムが死亡の場合、追跡期間が完了する前にセンサリングされる可能性が高いためです。

### モデル開発設定

予測モデルを開発するために、どのアルゴリズムを訓練するかを決める必要があります。ある予測問題に対する最良のアルゴリズムの選択は経験的な質問であり、データが自ら語るようにし、最適なものを見つけるために異なるアプローチを試みることを好みます。私たちのフレームワークでは、セクション \@ref(modelFitting)に記載されているように多くのアルゴリズムを実装し、他のアルゴリズムを追加することを許可しています。この例では、シンプルにするために、Gradient Boosting Machines（GBM）を一つのアルゴリズムとして選択します。

さらに、モデルを訓練するために使用する共変量を決定する必要があります。私たちの例では、性別、年齢、すべての疾患、薬剤および薬剤グループ、訪問回数を追加します。これらの臨床イベントはインデックス日以前の1年間およびインデックス日以前のいつでも検索します。

### モデル評価

最後に、どのようにモデルを評価するかを定義する必要があります。シンプルさを追求して、ここでは内部検証を選択します。データセット分割の方法や患者をトレーニングセットとテストセットに割り当てる方法について決定する必要があります。ここでは典型的な75％ - 25％の分割を使用します。非常に大規模なデータセットでは、より多くのデータをトレーニングに使用できます。

### 研究概要

これで、表 \@ref(tab:plpSummary) に示されるように、研究を完全に定義しました。

| 選択 | 値 |
|:---|:---|
| ターゲットコホート | 初めてACE阻害薬を開始した患者。以前の観察期間が365日未満、または以前に血管性浮腫がない患者は除外されます。 |
| アウトカムコホート | 血管性浮腫。 |
| リスク期間 | コホート開始後1日から365日。少なくとも364日のリスク期間が必要。 |
| モデル | Gradient Boosting Machine with hyper-parameters ntree: 5000, max depth: 4 or 7 or 10 and learning rate: 0.001 or 0.01 or 0.1 or 0.9. Covariates will include gender, age, conditions, drugs, drug groups, and visit count. データ分割: 75％トレーニング - 25％テスト、個人ごとにランダムに割り当てられます。 |

: (#tab:plpSummary) 私たちの研究の主な設計選択

## ATLASでの研究の実装

予測研究を設計するインターフェースは、ATLASメニューの左側にある![](images/PatientLevelPrediction/predictionButton.png)ボタンをクリックすることで開くことができます。新しい予測研究を作成しましょう。研究にわかりやすい名前をつけておくことを忘れないでください。研究の設計はいつでも![](images/PopulationLevelEstimation/save.png)ボタンをクリックして保存できます。\index{ATLAS}

予測設計機能には、予測の問題設定、分析設定、実行設定、トレーニング設定の4つのセクションがあります。それぞれのセクションについて説明します。

### 予測の問題設定

ここでは、分析の対象となる母集団コホート群とアウトカムコホートを選択します。予測モデルは、対象となる母集団コホートとアウトカムコホートの全組み合わせに対して開発されます。例えば、2つの対象集団と2つのアウトカムを指定すると、4つの予測問題が指定されたことになります。

対象となる母集団集団コホートを選択するには、事前にATLASで定義しておく必要があります。コホートのインスタンス化については、第 \@ref(Cohorts) 章で説明しています。この例で使用する対象（付録 \@ref(AceInhibitors)）およびアウトカム（付録 \@ref(Angioedema)）コホートの完全な定義は付録に掲載しています。対象集団をコホートに追加するには、「Add Target Cohort」ボタンをクリックします。アウトカムコホートの追加も同様に、「Add Outcome Cohort」ボタンをクリックすることで行います。完了すると、ダイアログが図 \@ref(fig:problemSettings) のようになります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/problemSettings} 

}

\caption{予測問題設定}(\#fig:problemSettings)
\end{figure}

### 分析設定

分析設定では、教師あり学習アルゴリズム、共変量と集団設定を選択できます。

#### モデル設定 {.unnumbered}

モデル開発のために1つ以上の教師あり学習アルゴリズムを選ぶことができます。教師あり学習アルゴリズムを追加するには、「Add Model Settings」ボタンをクリックします。現在ATLASインターフェースでサポートされているすべてのモデルを含むドロップダウンが表示されます。ドロップダウンメニューの名前をクリックすることで、研究に含めたい教師あり学習モデルを選択できます。これでその特定のモデルのビューが表示され、ハイパーパラメータ値を選択できるようになります。複数の値が提供されると、クロスバリデーションを使用して最適な組み合わせを選択するために、すべての可能な値の組み合わせを網羅的に検索します。

我々の例では、勾配ブースティングマシンを選択し、図 \@ref(fig:gbmSettings) に示すようにハイパーパラメータを設定します。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/gbmSettings} 

}

\caption{勾配ブースティングマシン設定}(\#fig:gbmSettings)
\end{figure}

#### 共変量設定 {.unnumbered}

CDM形式の観察データから抽出できる標準共変量のセットを定義しました。共変量設定ビューでは、含める標準共変量を選択できます。異なるタイプの共変量設定を定義でき、それぞれのモデルは指定された共変量設定ごとに個別に作成されます。

研究に共変量設定を追加するには、「Add Covariate Settings」をクリックします。これで共変量設定ビューが開きます。

共変量設定ビューの最初の部分は除外/包括オプションです。共変量は一般に任意のコンセプトに対して構築されますが、例えばターゲットコホート定義にリンクされている場合、特定のコンセプトを除外または含めることができます。特定のコンセプトのみを含めるには、ATLASでコンセプトセットを作成し、 "**What concepts do you want to include in baseline covariates in the patient-level prediction model? (Leave blank if you want to include everything) (患者レベルの予測モデルにおけるベースライン共変量として、どのようなコンセプトを含めたいですか？（すべてを含めたい場合は空白のままにしてください）)**" の下で![](images/PopulationLevelEstimation/open.png)をクリックしてコンセプトセットを選択します。コンセプトセット内のコンセプトに下位層コンセプトを自動的に追加するには、 "**Should descendant concepts be added to the list of included concepts? (含まれるコンセプトのリストに下位層コンセプトを追加すべきでしょうか？)**" の質問に「yes」と答えます。同じプロセスを、共変量に対応する選択されたコンセプトを除外する "**What concepts do you want to exclude in baseline covariates in the patient-level prediction model? (Leave blank if you want to include everything) (患者レベルの予測モデルにおけるベースライン共変量から除外したいコンセプトは何ですか？（すべてを含める場合は空白のままにしてください）)**" の質問にも繰り返します。最後のオプション "**A comma delimited list of covariate IDs that should be restricted to (制限すべき共変数IDのコンマ区切りリスト)**" では、共変量ID（コンセプトIDではなく）をカンマ区切りで追加し、これらがモデルに含まれるようにすることができます。このオプションは上級ユーザ向けです。完了すると、適格基準設定と除外基準設定は図 \@ref(fig:covariateSettings1)のようになります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings1} 

}

\caption{共変量の包括と除外設定}(\#fig:covariateSettings1)
\end{figure}

次のセクションでは、時間に依存しない変数の選択ができます：

-   性別： 男性または女性の性別を示す二値変数

-   年齢： 年単位の連続変数

-   年齢グループ： 5年ごとのバイナリ変数（0-4、5-9、...、95+）

-   人種： 各人種に関するバイナリ変数で、1は患者がその人種を記録していることを意味し、0はそうでないことを意味します。

-   民族： 各民族性に関するバイナリ変数で、1は患者がその民族性を記録していることを意味し、0はそうでないことを意味します。

-   インデックス年： 各コホート開始日の年を表すバイナリ変数で、1は患者のコホート開始年、0はそれ以外を表します。**インデックス年を含めることは、しばしば意味をなさないことがあります。なぜなら、私たちは将来にわたってモデルを適用したいからです**。

-   インデックス月： 各コホート開始日の月を表すバイナリ変数で、1は患者のコホート開始日の月を表し、0はそれ以外を表します。

-   前観察期間： [予測には推奨されません] コホート開始日以前に患者がデータベースに存在した日数に相当する連続変数

-   後観察期間： [予測には推奨されません] 患者がコホート開始日以降データベースに存在した日数に相当する連続変数

-   コホート時間： 患者がコホートに属していた日数（コホート終了日－コホート開始日）に対応する連続変数

-   インデックス年と月： [予測には推奨されません] 各コホート開始日の年と月の組み合わせを表すバイナリ変数。1は患者のコホート開始日の年と月であることを表し、0はそれ以外を表します。

これが完了すると、このセクションは図 \@ref(fig:covariateSettings2) のようになるはずです。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings2} 

}

\caption{共変量の選択}(\#fig:covariateSettings2)
\end{figure}

標準共変量は共変量の柔軟な3つの時間間隔を可能にします：

-   終了日までの日数: コホート開始日からの終了日まで[デフォルトは0]
-   長期 [デフォルトはコホート開始前365日から終了日まで]
-   中期 [デフォルトはコホート開始前180日から終了日まで]
-   短期 [デフォルトはコホート開始前30日から終了日まで]

これが完了すると、このセクションは図 \@ref(fig:covariateSettings3) のようになるはずです。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings3} 

}

\caption{時間に依存する共変量}(\#fig:covariateSettings3)
\end{figure}

次のオプションは、期間テーブルから抽出される共変量です：

-   コンディション： 選択された各コンディションコンセプトIDと時間間隔ごとに共変量を構築し、CONDITON_ERAテーブルにおいて、選択されたコホート開始日前の時間間隔の間に、患者にコンディション期間をもつ（すなわち、その時間間隔の間にそのコンディションが開始または終了するか、またはその時間間隔の前に開始し、その時間間隔の後に終了する）コンセプトIDがある場合、共変量の値は 1、そうでない場合は 0。

-   コンディショングループ： 選択されたコンディションコンセプトIDと時間間隔ごとに共変量を構築し、CONDITON_ERAテーブルにおいて、選択されたコホート開始日前の時間間隔の間に、患者にコンディション期間を持つコンセプトID**またはその下位層のコンセプトID**がある場合、共変量値は 1、そうでない場合は 0。

-   薬剤：選択された各薬剤コンセプトIDと時間間隔ごとに共変量を構築し、DRUG_ERAテーブルにおいて、選択されたコホート開始日前の時間間隔の間に、患者に薬剤（曝露）期間をもつコンセプトIDがある場合、共変量の値は 1、そうでない場合は 0。

-   薬剤グループ：選択された各薬剤コンセプトIDと時間間隔ごとに共変量を構築し、DRUG_ERAテーブルにおいて、選択されたコホート開始日前の時間間隔の間に、患者に薬剤（曝露）期間をもつコンセプトID**またはその下位層のコンセプトID**がある場合、共変量の値は 1、そうでない場合は 0。

オーバーラップ設定には、薬剤または症状がコホート開始日以前に開始し、終了がコホート開始日以後に続くものが含まれます。**期間の開始**オプションは時間間隔内に開始したものに限定します。

これが完了すると、このセクションは図 \@ref(fig:covariateSettings4) のようになるはずです。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings4} 

}

\caption{期間時間共変量.}(\#fig:covariateSettings4)
\end{figure}

次のオプションは、各ドメインでのコンセプトIDに基づく共変量に基づきます：

-   コンディション： 選択されたコンディションコンセプトIDと時間間隔ごとに共変量を構築し、CONDITION_OCCURRENCテーブルのコホート開始日前の指定された時間間隔に、患者がそのコンセプトIDを記録している場合、共変量の値は1、そうでない場合は0。

-   主たる入院コンディション（Condition Primary Inpatient）： condition_occurrenceテーブルで入院患者の主たる診断として、CONDITION_OCCURRENCテーブル中に観察されたコンディションごとのバイナリ共変量。

-   薬剤： 選択された薬剤コンセプトIDと時間間隔ごとに共変量を構築し、DRUG_EXPOSUREテーブルのコホート開始日前の指定された時間間隔に、患者がコンセプトIDを記録している場合、共変量の値は 1 、そうでない場合は 0。

-   処置（プロシージャー）：選択された処置コンセプトIDと時間間隔ごとに共変量を構築し、PROCEDURE_OCCURRENCEテーブルのコホート開始日前の指定された時間間隔に、患者がコンセプトIDを記録している場合、共変量の値は 1 、そうでない場合は 0。

-   測定（メジャーメント）：選択された測定コンセプトIDと時間間隔ごとに共変量を構築し、MEASUREMENTテーブルのコホート開始日前の指定された時間間隔に、患者がコンセプトIDを記録している場合、共変量の値は 1 、そうでない場合は 0。

-   測定値： 測定値が伴う選択された測定コンセプトIDと時間間隔ごとに共変量を構築し、MEASUREMENTテーブルのコホート開始日前の指定された時間間隔に、患者がコンセプトIDを記録している場合、共変量の値は 1 、そうでない場合は 0。

-   測定値範囲グループ： 測定値が正常範囲以下、範囲内、または正常範囲以上であるかを示すバイナリ共変量。

-   観察（オブザベーション）：選択された観察コンセプトIDと時間間隔ごとに共変量を構築し、OBSERVATIONテーブルのコホート開始日前の指定された時間間隔に、患者がそのコンセプトIDを記録している場合、共変量の値は1、そうでない場合は0。

-   デバイス：選択されたデバイスコンセプトIDと時間間隔ごとに共変量を構築し、DEVICEテーブルのコホート開始日前の指定された時間間隔に、患者がそのコンセプトIDを記録している場合、共変量の値は1、そうでない場合は0。

-   ビジット回数：選択されたビジット回数と時間間隔ごとに共変量を構築し、その時間間隔に記録されたビジット回数を共 変量値としてカウントします。

-   ビジットコンセプト数： 選択された各ビジット、ドメイン、および時間間隔ごとに共変量を構築し、その時間間隔に記録されたレコード数を、各ドメインのビジットタイプと時間間隔ごとに共変量値としてカウントします。

"distinct count (重複を除いたカウント)"オプションは、ドメインと時間間隔ごとに、異なるコンセプトIDの数をカウントします。

これらが終了すると、このセクションは下図 \@ref(fig:covariateSettings5) の様になっているはずです。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings5} 

}

\caption{時間制約共変量}(\#fig:covariateSettings5)
\end{figure}

最後のオプションは、一般的に使われるリスクスコアを共変量として含めるかどうかです。設定が完了すると、リスクスコアの設定は図 \@ref(fig:covariateSettings6) のようになります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/covariateSettings6} 

}

\caption{リスクスコア共変量設定}(\#fig:covariateSettings6)
\end{figure}

#### 研究対象集団設定 {.unnumbered}

対象集団の設定は、追加の適格基準をターゲット集団に適用できる場所であり、また、リスク時間もここで定義されます。 研究に対象集団の設定を追加するには、"Add Population Settings (対象集団の追加)" ボタンをクリックします。 これにより、対象集団の設定ビューが表示されます。

最初のオプションセットでは、リスク時間を指定することができます。これは、関心の対象であるアウトカムが出現するかどうかを観察する時間間隔です。リスク時間中に患者にアウトカムが出現した場合は "Has outcome (アウトカムあり)" に分類し、そうでない場合は "Has outcome (アウトカムなし)" に分類します。"**Define the time-at-risk window start, relative to target cohort entry: (ターゲットコホートの開始または終了日を基準とした、リスク時間ウインドウの開始を定義します。)** は、リスク時間ウインドウの開始を定義します。同様に、"**Define the time-at-risk window end: (ターゲットコホートの開始または終了日を基準とした、リスク時間ウインドウの終了を定義します。)** は、リスク時間ウインドウの終了を定義します。

"**Minimum lookback period applied to target cohort (ターゲットコホートに適用される最小のルックバック期間)**" は、患者がコホート開始日より前の継続的に観察された日数の最低値である、最小ベースライン期間を指定します。デフォルトは365日です。最小のルックバック期間を長くすると、患者の全体像がより明確になりますが（より長い期間観察されているはずであるため）、開始日前の観察が最低日数に満たない患者は除外されます。

"**Should subjects without time at risk be removed? (リスク時間がない対象は除外すべきですか。)"** が "Yes (はい)" に設定されている場合、"**Minimum time at risk: (最低リスク時間：)"** の値も必要となります。これにより、追跡不能となった人（すなわち、リスク時間中にデータベースから脱落した人）を除外することができます。例えば、リスク時間がコホート開始後1日からコホート開始後365日までであった場合、リスク時間は364日間（365-1）となります。もし、その全期間にわたって観察された患者のみを含めたいのであれば、最小リスク時間を364に設定します。最初の100日間リスク時間に該当していればよいのであれば、最小リスク期間を100に設定します。この場合、リスク時間開始はコホート開始から1日後なので、コホート開始日から少なくとも101日間データベースに存在する患者が対象となります。"Should subjects without time at risk be removed? (リスク時間がない対象は削除すべきですか。）" を "No (いいえ)" に設定すると、リスク期間中にデータベースから脱落した患者も含め、すべての患者が対象となります。

"**Include people with outcomes who are not observed for the whole at risk period? (全リスク時間で観察されていないアウトカムを持つ人々を含めますか。)** というオプションは、前のオプションに関連しています。 "Yes (はい)" に設定すると、指定された最低リスク時間で観察されていない場合でも、リスク時間中にアウトカムを経験した人は常にコホートに保持されます。

"**Should only the first exposure per subject be included? (対象ごとに最初の曝露のみを含めるべきですか)**" というオプションは、ターゲットコホートに異なるコホート開始日で複数回含まれる患者がいる場合にのみ有用です。この状況で "Yes (はい)" を選択すると、分析では患者ごとに最も早いターゲットコホートの日付のみが保持されます。そうでない場合、患者はデータセットに複数回含まれる可能性があります。

"**Remove patients who have observed the outcome prior to cohort entry? (コホート組入れの前にアウトカムが観察された患者を除外しますか)**" を "Yes (はい)" に設定すると、リスク時間開始日より前にアウトカムを経験した患者を除外するため、そのモデルは以前にアウトカムを経験したことがない患者を対象とします。もし "No (いいえ)" が選択されると、患者は以前にアウトカムを持つ可能性があります。患者が以前にアウトカムを経験したことが、リスク時間中にアウトカムが出現することを非常に高い確率で予測することが多いです。

完了すると、対象集団設定のダイアログは図 \@ref(fig:populationSettings) のようになります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/populationSettings} 

}

\caption{対象集団設定}(\#fig:populationSettings)
\end{figure}

これで分析の設定が終わり、ダイアログ全体が図 \@ref(fig:analysisSettings) になります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/analysisSettings} 

}

\caption{分析の設定}(\#fig:analysisSettings)
\end{figure}

### 実行の設定

オプションは3つあります：

-   **Perform sampling (サンプリングの実行)** ： ここでサンプリングを実行するかどうかを選択します（デフォルトは "no (いいえ)"）。"yes (はい)" に設定すると、別のオプションが表示されます： "**How many patients to use for a subset? (サブセットに何人の患者を含めますか。)**" で、サンプルの大きさを指定できます。サンプリングは、患者のサンプルでモデルを作成してテストすることにより、大規模な集団（例えば、1,000万人の患者）に対するモデルが予測可能かどうかを決定する効率的な手段となります。例えば、サンプルでAUCが0.5に近い場合、そのモデルを放棄するかもしれません。

-   "**Minimum covariate occurrence: If a covariate occurs in a fraction of the target population less than this value, it will be removed: (最小共変量出現率： もし共変量がこの値より小さい割合でターゲット集団に出現する場合、その共変量は除外されます:)**": ここでは共変量の出現率の最小値を選択します（デフォルトは0.001）。共変量出現の最小閾値は、全体集団を代表しないまれなイベントを除外するために必要です。

-   "**Normalize covariate (共変量を正規化する)**"： ここで共変量を正規化するかどうかを選択します（デフォルトは "yes (はい)"）。共変量の正規化は、通常、LASSOモデルをうまく実行するために必要です。

この例では、図 \@ref(fig:executionSettings) のように選択します。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/executionSettings} 

}

\caption{実行の設定}(\#fig:executionSettings)
\end{figure}

### トレーニングの設定

4つのオプションがあります：

-   "**Specify how to split the test/train set (テストセットとトレーニングセットをどのように分けるかを指定します。)**"： トレーニング/テストデータを人別（アウトカムで層別化）または時間別（古いデータをトレーニングに、新しいデータは評価に）に分割するかを選択します。

-   "**Percentage of the data to be used as the test set (0-100%) (テストセットとして使用するデータの割合(0-100%))**"： テストデータとして使用するデータの割合を選択します（デフォルトは25%）。

-   "**The number of folds used in the cross validation (クロスバリデーションで使用するフォールド数)**"： 最適なハイパーパラメータを選択するために使用するクロスバリデーションのフォールド数を選択します（デフォルトは3）。

-   "**The seed used to split the test/train set when using a person type testSplit (optional): (人単位で testSplit を使う場合の、テストセットとトレーニングセットを分割するためのシード (オプション)：)**"： 人単位でテストセットとトレーニングセットを分割する場合に、分割に使用する乱数のシードを選択します。

この例では、図 \@ref(fig:trainingSettings) のように選択します。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/trainingSettings} 

}

\caption{トレーニングの設定}(\#fig:trainingSettings)
\end{figure}

### 研究のインポートとエクスポート

研究をエクスポートするには、"Utilities (ユーティリティ)" の下にある "Export (エクスポート)" タブをクリックします。ATLASは、研究の名称、コホート定義、選択したモデル、共変量、設定など、研究実行に必要なすべてのデータを含むファイルに直接コピー＆ペーストできるJSONを作成します。

研究をインポートするには、"Utilities (ユーティリティ)" の下にある "Import (インポート)" タブをクリックします。患者レベルの予測研究のJSONの内容をこのウィンドウに貼り付け、他のタブボタンの下にある "Import (インポート)" ボタンをクリックします。これにより、その研究の以前の設定がすべて上書きされることに注意してください。

### 研究パッケージのダウンロード

"Utilities (ユーティリティ)" の下にある "Review & Download (レビューとダウンロード)"」レビューとダウンロード " タブをクリックします。"Download Study Package (研究パッケージをダウンロード)" セクションで、Rパッケージのわかりやすい名前を入力します。Rで使えない文字は、ATLASによって自動的にファイル名から削除されることに注意してください。![](images/PatientLevelPrediction/download.png) をクリックして、Rパッケージをローカルフォルダにダウンロードします。

### 研究の実行

セクション \@ref(installR) の説明のように、Rパッケージを実行するには、R、RStudio、Javaがインストールされている必要があります。また、Rで下記のようにインストールできる [PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) パッケージも必要です：


``` r
install.packages("drat")
drat::addRepo("OHDSI")
install.packages("PatientLevelPrediction")
```

機械学習アルゴリズムの中には、追加ソフトウェアのインストールが必要なものがあります。[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/) パッケージのインストール方法の詳細については、["Patient-Level Prediction Installation Guide" vignette](https://ohdsi.github.io/PatientLevelPrediction/articles/InstallationGuide.html)を参照してください。

study Rパッケージを使用するには、R Studioの使用をお勧めします。R Studioをローカルで実行している場合は、ATLASで生成されたファイルを解凍し、.RprojファイルをダブルクリックしてR Studioで開きます。RスタジオをRスタジオサーバーで実行している場合は、![](images/PopulationLevelEstimation/upload.png)をクリックしてファイルをアップロードし、解凍した後、.Rprojファイルをクリックしてプロジェクトを開きます。

R Studioでプロジェクトを開いたら、READMEファイルを開き、指示に従ってください。すべてのファイルのパスを、システム上の既存のパスに変更してください。

## Rでの研究実施

研究デザインをATLASで実装する代わりに、Rで直接コードを記述して実施することもできます。ここでは、[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/)パッケージを利用します。このパッケージは、OMOP CDMに変換されたデータベースからデータを抽出し、モデルを構築し、評価することができます。

### コホートのインスタンス化

まず、ターゲットコホートとアウトカムコホートをインスタンス化する必要があります。コホートのインスタンス化については、第 \@ref(Cohorts) 章で説明しています。付録にはターゲットコホート(付録 \@ref(AceInhibitors))とアウトカムコホート(付録 \@ref(Angioedema))の完全な定義があります。この例では、ACE阻害薬コホートのIDが1、血管浮腫コホートのIDが2であると仮定します。

### データ抽出

まず、Rにサーバへの接続方法を伝える必要があります。[`PatientLevelPrediction`](https://ohdsi.github.io/PatientLevelPrediction/)は、[`DatabaseConnector`](https://ohdsi.github.io/DatabaseConnector/)パッケージを使用します。このパッケージには`createConnectionDetails`という関数があります。さまざまなデータベース管理システム(DBMS)の設定については、`?createConnectionDetails`と入力してください。例えば、次のようにPostgreSQLデータベースに接続できます：


``` r
library(PatientLevelPrediction)
connDetails <- createConnectionDetails(dbms = "postgresql",
                                       server = "localhost/ohdsi",
                                       user = "joe",
                                       password = "supersecret")

cdmDbSchema <- "my_cdm_data"
cohortsDbSchema <- "scratch"
cohortsDbTable <- "my_cohorts"
cdmVersion <- "5"
```

最後の4行は`cdmDbSchema`、`cohortsDbSchema`、`cohortsDbTable`変数の定義と、CDMバージョンを指定しています。これらを使用してCDMフォーマットのデータが存在する場所、関心のあるコホートが作成された場所、および使用されているCDMバージョンをRに伝えます。Microsoft SQL Serverの場合、データベーススキーマはデータベースとスキーマの両方を指定する必要があることに注意してください。例えば、`cdmDbSchema <- "my_cdm_data.dbo"`のように指定します。

まず、コホート作成が成功したかを確認するために、コホートエントリの数をカウントします：


``` r
sql <- paste("SELECT cohort_definition_id, COUNT(*) AS count",
"FROM @cohortsDbSchema.cohortsDbTable",
"GROUP BY cohort_definition_id")
conn <- connect(connDetails)
renderTranslateQuerySql(connection = conn,
                        sql = sql,
                        cohortsDbSchema = cohortsDbSchema,
                        cohortsDbTable = cohortsDbTable)
```


```
##   cohort_definition_id  count
## 1                    1 527616
## 2                    2   3201
```

[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/)に我々の分析に必要なすべてのデータを抽出するように指示します。共変量は[`FeatureExtraction`](https://ohdsi.github.io/FeatureExtraction/)パッケージを使用して抽出します。FeatureExtractionパッケージの詳細については、そのビネットを参照してください。今回の研究例では次の設定を使用しました：


``` r
covariateSettings <- createCovariateSettings(
  useDemographicsGender = TRUE,
  useDemographicsAge = TRUE,
  useConditionGroupEraLongTerm = TRUE,
  useConditionGroupEraAnyTimePrior = TRUE,
  useDrugGroupEraLongTerm = TRUE,
  useDrugGroupEraAnyTimePrior = TRUE,
  useVisitConceptCountLongTerm = TRUE,
  longTermStartDays = -365,
  endDays = -1)
```

データ抽出の最終ステップは、`getPlpData`関数を実行し、接続詳細、コホートが保存されているデータベーススキーマ、コホートとアウトカムの定義ID、洗い出し期間（最小観察日数）、および前述の共変量設定を入力することです。


``` r
plpData <- getPlpData(connectionDetails = connDetails,
                      cdmDatabaseSchema = cdmDbSchema,
                      cohortDatabaseSchema = cohortsDbSchema,
                      cohortTable = cohortsDbSchema,
                      cohortId = 1,
                      covariateSettings = covariateSettings,
                      outcomeDatabaseSchema = cohortsDbSchema,
                      outcomeTable = cohortsDbSchema,
                      outcomeIds = 2,
                      sampleSize = 10000
)
```

`getPlpData`関数には多くの追加パラメータがあります。これらはすべて[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/)マニュアルに詳細に記載されています。生成された`plpData`オブジェクトは`ff`パッケージを使用し、大量のデータでもRのメモリ不足を避けるように設計されています。

`plpData`オブジェクトの生成にはかなりの計算時間がかかることがあり、将来のセッションのために保存することが賢明です。`plpData`は`ff`を使用しているため、Rの通常の保存機能は使用できません。代わりに`savePlpData`関数を使用します：


``` r
savePlpData(plpData, "angio_in_ace_data")
```

将来的なセッションでデータをロードするには`loadPlpData()`関数を使用します。

### 追加選択基準

最終的な研究対象集団は、前述の2つのコホートに追加の制約を適用することによって得られます。例えば、最小リスク期間を設定することができます（`requireTimeAtRisk`、`minTimeAtRisk`）し、これがアウトカムを持つ患者にも適用されるかどうかを指定できます（`includeAllOutcomes`）。ここでは、リスクウィンドウの開始と終了をターゲットコホートの開始日相対に指定します。例えば、リスクウィンドウを集計開始から30日後に開始し、1年後に終了させる場合、`riskWindowStart = 30`、`riskWindowEnd = 365`と設定します。場合によっては、リスクウィンドウをコホート終了日に開始する必要があります。これは、`addExposureToStart = TRUE`を設定し、コホート（曝露）期間を開始日に加算することで実現できます。

以下の例では、我々の研究のために定義したすべての設定を適用します：


``` r
population <- createStudyPopulation(plpData = plpData,
                                    outcomeId = 2,
                                    washoutPeriod = 364,
                                    firstExposureOnly = FALSE,
                                    removeSubjectsWithPriorOutcome = TRUE,
                                    priorOutcomeLookback = 9999,
                                    riskWindowStart = 1,
                                    riskWindowEnd = 365,
                                    addExposureDaysToStart = FALSE,
                                    addExposureDaysToEnd = FALSE,
                                    minTimeAtRisk = 364,
                                    requireTimeAtRisk = TRUE,
                                    includeAllOutcomes = TRUE,
                                    verbosity = "DEBUG"
)
```

### モデル開発

アルゴリズムの設定関数において、ユーザーは各ハイパーパラメータの候補値のリストを指定できます。すべてのハイパーパラメータの組み合わせが、トレーニングセットでクロスバリデーションを行うグリッドサーチに含まれます。ユーザーが特定の値を指定しない場合は、デフォルト値が使用されます。

例えば、次の設定をグラデーションブースティングマシン（Gradient Boosting Machine）で使用するとします：`ntrees = c(100,200)`, `maxDepth = 4`。このグリッドサーチは、`ntrees = 100`および`maxDepth = 4`、または`ntrees = 200`および`maxDepth = 4`の設定でデフォルトの他のハイパーパラメータ設定を含めてグラデーションブースティングマシンアルゴリズムを適用します。クロスバリデーションのパフォーマンスが最も高いハイパーパラメータが最終モデルに選ばれます。我々の課題では、いくつかのハイパーパラメータ値でグラデーションブースティングマシンを構築することを選びました：


``` r
gbmModel <- setGradientBoostingMachine(ntrees = 5000,
                                       maxDepth = c(4,7,10),
                                       learnRate = c(0.001,0.01,0.1,0.9))
```

`runPlP`関数は集団、`plpData`、およびモデル設定を使用してモデルをトレーニングし評価します。データを75%-25%に分割して患者レベルの予測パイプラインを実行するために`testSplit`（人/時間）および`testFraction`パラメータを使用できます：


``` r
gbmResults <- runPlp(population = population,
                     plpData = plpData,
                     modelSettings = gbmModel,
                     testSplit = 'person',
                     testFraction = 0.25,
                     nfold = 2,
                     splitSeed = 1234)
```

このパッケージは内部的にRのxgboostパッケージを使用して、75%のデータを用いてグラデーションブースティングマシンモデルを適合させ、残りの25%のデータでモデルを評価します。アウトカムデータ構造には、モデルやそのパフォーマンスなどに関する情報が含まれます。

`runPlp`関数には、`plpData`、`plpResults`、`plpPlots`、`evaluation`などのオブジェクトを保存するためのいくつかのパラメータがあり、デフォルトで`TRUE`に設定されています。

モデルを保存するには：


``` r
savePlpModel(gbmResults$model, dirPath = "model")
```

モデルをロードするには：


``` r
plpModel <- loadPlpModel("model")
```

完全なアウトカム構造を保存することもできます：


``` r
savePlpResult(gbmResults, location = "gbmResults")
```

完全なアウトカム構造をロードするには：


``` r
gbmResults <- loadPlpResult("gbmResults")
```

### 内部バリデーション

研究を実行すると、`runPlp`関数はトレーニング済みモデルとトレイン/テストセットに対するモデルの評価を返します。アウトカムをインタラクティブに表示するには、`viewPlp(runPlp = gbmResults)`を実行します。これによりShinyアプリケーションが開き、フレームワークによって作成されたすべてのパフォーマンス指標を含むインタラクティブなプロットを表示できます（Shinyアプリケーションのセクション内の図 \@ref(fig:shinySummary)参照）。

評価プロットをフォルダーに生成して保存するには、次のコードを実行します：


``` r
plotPlp(gbmResults, "plots")
```

プロットの詳細については、セクション \@ref(performance)を参照してください。

### 外部バリデーション

いつでも外部バリデーションを行うことをお勧めします。すなわち、最終モデルを可能な限り新しいデータセットに適用し、そのパフォーマンスを評価します。ここでは、データ抽出がすでに行われ、`newData`フォルダーに保存されたことを仮定します。以前にフィッティングしたモデルを`model`フォルダーからロードします：


``` r
# トレーニング済みモデルをロード
plpModel <- loadPlpModel("model")

# 新しいplpDataをロードし、集団を作成
plpData <- loadPlpData("newData")

population <- createStudyPopulation(plpData = plpData,
                                    outcomeId = 2,
                                    washoutPeriod = 364,
                                    firstExposureOnly = FALSE,
                                    removeSubjectsWithPriorOutcome = TRUE,
                                    priorOutcomeLookback = 9999,
                                    riskWindowStart = 1,
                                    riskWindowEnd = 365,
                                    addExposureDaysToStart = FALSE,
                                    addExposureDaysToEnd = FALSE,
                                    minTimeAtRisk = 364,
                                    requireTimeAtRisk = TRUE,
                                    includeAllOutcomes = TRUE
)

# apply the trained model on the new data
validationResults <- applyModel(population, plpData, plpModel)
```

さらに簡単にできるように、必要なデータの抽出も行う外部検証を行うための `externalValidatePlp` 関数も提供しています。 `result <- runPlp(...)` を実行したと仮定すると、モデルに必要なデータを抽出して、新しいデータで評価することができます。検証対象集団が ID 1 と 2 のテーブル `mainschema.dob.cohort` にあり、CDM データがスキーマ `cdmschema.dob` にあると仮定すると：


``` r
valResult <- externalValidatePlp(
	plpResult = result,
	connectionDetails = connectionDetails,
	validationSchemaTarget = 'mainschema.dob',
	validationSchemaOutcome = 'mainschema.dob',
	validationSchemaCdm = 'cdmschema.dbo',
	databaseNames = 'new database',
	validationTableTarget = 'cohort',
	validationTableOutcome = 'cohort',
	validationIdTarget = 1,
	validationIdOutcome = 2
)
```

モデルを検証する複数のデータベースがある場合、以下を実行できます：


``` r
valResults <- externalValidatePlp(
	plpResult = result,
	connectionDetails = connectionDetails,
	validationSchemaTarget = list('mainschema.dob',
								'difschema.dob',
								'anotherschema.dob'),
	validationSchemaOutcome = list('mainschema.dob',
								 'difschema.dob',
								 'anotherschema.dob'),
	validationSchemaCdm = list('cdms1chema.dbo',
							 'cdm2schema.dbo',
							 'cdm3schema.dbo'),
	databaseNames = list('new database 1',
					   'new database 2',
					   'new database 3'),
	validationTableTarget = list('cohort1',
							   'cohort2',
							   'cohort3'),
	validationTableOutcome = list('cohort1',
								'cohort2',
								'cohort3'),
	validationIdTarget = list(1,3,5),
	validationIdOutcome = list(2,4,6)
)
```

## アウトカム普及

### モデルパフォーマンス

予測モデルのパフォーマンスを探索する最も簡単な方法は、`viewPlp`関数を使用することです。これはアウトカムオブジェクトを入力として必要とします。Rでモデルを開発する場合、`runPLp`のアウトカムを入力として使用できます。ATLASで生成された研究パッケージを使用する場合は、モデルの1つを読み込む必要があります（この例ではAnalysis_1を読み込みます）。\index{model viewer app}


``` r
plpResult <- loadPlpResult(file.path(outputFolder,
                                     'Analysis_1',
                                     'plpResult'))
```

ここで「Analysis_1」は以前に特定した分析に対応しています。

次に、以下を実行してShinyアプリケーションを起動できます。


``` r
viewPlp(plpResult)
```

Shinyアプリケーションはテストセットとトレインセットのパフォーマンス指標の要約から始まります（図 \@ref(fig:shinySummary) 参照）。アウトカムは、トレインセットのAUCは0.78であり、これがテストセットでは0.74に低下したことを示しています。テストセットのAUCがより正確な測定値です。全体として、モデルはACE阻害剤の新規ユーザーの中でアウトカムを発生させる人を識別する能力があるようですが、トレインセットのパフォーマンスがテストセットより高いため、わずかに過適合しています。ROCプロットは図 \@ref(fig:shinyROC)に示されています。

\begin{figure}
\includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shinysummary} \caption{Shinyアプリケーションにおける評価統計の要約}(\#fig:shinySummary)
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/singleShiny/singleShinyRoc} 

}

\caption{ROCプロット}(\#fig:shinyROC)
\end{figure}

図 \@ref(fig:shinyCal) に示されているキャリブレーションプロットは、一般的に観察されたリスクが予測されたリスクと一致していることを示しており、点が対角線の周りにあります。しかし、図 \@ref(fig:shinyDemo) に示されている人口統計学的キャリブレーションプロットは、40歳未満の若年患者についてモデルが十分に校正されていないことを示しています。青い線（予測リスク）は赤い線（観察されたリスク）とは異なります。これは、ターゲット人口から40歳未満を除外する必要があることを示しているかもしれません（若年患者の観察リスクはほとんどゼロです）。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/singleShiny/singleShinyCal} 

}

\caption{モデルのキャリブレーション}(\#fig:shinyCal)
\end{figure}

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/singleShiny/singleShinyDemo} 

}

\caption{モデルの人口統計学的キャリブレーション}(\#fig:shinyDemo)
\end{figure}

最後に、選択基準に基づくラベル付きデータからの患者の脱落を示すattritionプロットがあります（図 \@ref(fig:shinyAtt)参照）。プロットは、リスク期間全体で観察されていなかったため、ターゲット人口の大部分が失われたことを示しています（1年間のフォローアップ）。興味深いことに、アウトカムが出た患者の多くは完全なリスク期間を欠いていませんでした。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/singleShiny/singleShinyAtt} 

}

\caption{予測問題におけるattritionプロット}(\#fig:shinyAtt)
\end{figure}

### モデルの比較

ATLASで生成されたスタディパッケージは、異なる予測問題に対して多くの異なる予測モデルを生成および評価することができます。したがって、研究パッケージによって生成された出力専用に、複数のモデルを表示する追加のShinyアプリが開発されました。このアプリを起動するには、`viewMultiplePlp(outputFolder)`を実行します。ここで`outputFolder`は、`execute`コマンドを実行したときに指定した分析アウトカムを含むパスです（そして例として「Analysis_1」というサブフォルダーを含んでいる必要があります）。

#### モデルの要約と設定の表示 {.unnumbered}

インタラクティブなShinyアプリは、図 \@ref(fig:multiShinySummary)に示す要約ページから始まります。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyFilter} 

}

\caption{各モデルのホールドアウトセットの主要なパフォーマンス指標を含むShinyの要約ページ}(\#fig:multiShinySummary)
\end{figure}

この要約ページの表には以下が含まれています：

-   モデルに関する基本情報（例：データベース情報、分類器タイプ、リスク期間設定、ターゲット集団およびアウトカム名）
-   ホールドアウトターゲット人口数およびアウトカム発生率
-   判別指標：AUC、AUPRC

テーブルの左側にはフィルターオプションがあり、開発/検証データベース、モデルの種類、関心のあるリスク期間設定および/または関心のあるコホートを指定できます。例えば、ターゲットコホートオプションで「高血圧の第一選択の単剤療法としてのACE阻害剤の新規ユーザー」に対応するモデルを選択します。

モデルを詳細に探るには、対応する行をクリックします。選択された行はハイライト表示されます。行が選択されると、「Model Settings」タブをクリックしてモデルを開発する際に使用した設定を調べることができます。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyModel} 

}

\caption{モデルを開発する際に使用した設定を表示する}(\#fig:shinyModel)
\end{figure}

同様に、他のタブでモデルを生成するために使用された人口および共変量の設定を調べることもできます。

#### モデルパフォーマンスの表示 {.unnumbered}

モデル行が選択されると、モデルパフォーマンスも表示できます。![](images/PatientLevelPrediction/performance.png) をクリックしてしきい値パフォーマンスの要約を表示します（図 \@ref(fig:shinyPerformanceSum)参照）。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyPerformanceSum} 

}

\caption{特定のしきい値におけるパフォーマンス測定の要約}(\#fig:shinyPerformanceSum)
\end{figure}

この要約ビューは標準形式で選択された予測問題を表示し、しきい値セレクタと正の予測値（PPV）、負の予測値（NPV）、感度および特異度（セクション \@ref(performance) 参照）などの重要なしきい値ベースの指標を含むダッシュボードを表示します。図 \@ref(fig:shinyPerformanceSum) では、しきい値が0.00482で感度は83.4％（翌年のアウトカムを持つ患者の83.4％がリスク0.00482以上）、PPVは1.2％（リスク0.00482以上の患者の1.2％が翌年にアウトカムを持つ）であることが示されている。1年以内のアウトカム発生率が0.741％であることを考えると、リスクが0.00482以上の患者を特定することで、集団平均リスクの約2倍のリスクを持つサブグループを見つけることができます。スライダーを使用してしきい値を調整し、他の値でのパフォーマンスを表示できます。

モデル全体の判別を確認するには、「Discrimination」タブをクリックしてROCプロット、精度-再現プロット、および分布プロットを表示します。プロットの線は選択されたしきい値ポイントに対応しています。図 \@ref(fig:shinyPerformanceDisc) はROCおよび精度-再現プロットを示しています。ROCプロットは、モデルが翌年にアウトカムが発生する人と発生しない人を区別できることを示しています。しかし、アウトカム発生率が低いため、精度-再現プロットを見るとパフォーマンスはそれほど印象的でないように見えます。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyPerformanceDisc} 

}

\caption{ROCおよび精度-再現プロットを使用してモデルの判別能力全体を評価する}(\#fig:shinyPerformanceDisc)
\end{figure}

図 \@ref(fig:shinyPerformanceDist) は予測リスクおよび選好スコア分布を示しています。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyPerformanceDist} 

}

\caption{アウトカム有およびアoutingの患者に対する予測リスク分布。重なりが多いほど、判別が悪化します。}(\#fig:shinyPerformanceDist)
\end{figure}

最後に、「Calibration」タブをクリックしてモデルのキャリブレーションを確認することもできます。これにより、図 \@ref(fig:shinyPerformanceCal) に示されるキャリブレーションプロットおよび人口統計学的キャリブレーションが表示されます。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyPerformanceCal} 

}

\caption{リスク層別キャリブレーションおよび人口統計学的キャリブレーション}(\#fig:shinyPerformanceCal)
\end{figure}

1年以内のアウトカムを経験したグループの予測リスクと観察されたアウトカムの割合が一致しているように見えるので、モデルはよく校正されています。興味深いことに、人口統計学的キャリブレーションは、若年患者の場合、予測されたリスクが観察されたリスクよりも高いことを示しています。逆に80歳以上の患者の場合、モデルは観察されたリスクよりも低いリスクを予測しています。これは、若年および高齢者のために別々のモデルを開発する必要があることを示唆しているかもしれません。

#### モデルの表示 {.unnumbered}

最終モデルを検査するには、左側のメニューから![](images/PatientLevelPrediction/modelButton.png)オプションを選択します。これにより、図 \@ref(fig:shinyModelPlots) に示すモデル内の各変数のプロットと図 \@ref(fig:shinyModelTable) に示すすべての候補共変量を要約するテーブルが表示されます。変数プロットはバイナリ変数と連続変数に分かれています。X軸はアウトカムがない患者の中での有病率/平均値、Y軸はアウトカムがある患者の中での有病率/平均値です。従って、変数の点が対角線の上にある場合、その変数はアウトカムがある患者の方が一般的であり、点が対角線の下にある場合、その変数はアウトカムがない患者の方が一般的です。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyModelPlots} 

}

\caption{モデル要約プロット。各点はモデルに含まれる変数に対応します。}(\#fig:shinyModelPlots)
\end{figure}

図 \@ref(fig:shinyModelTable)に示すテーブルでは、すべての候補共変量の名前、値（一般線形モデルを使用する場合は係数、その他の場合は変数の重要性）、アウトカム平均（アウトカムがある患者の平均値）、非アウトカム平均（アウトカムがない患者の平均値）が表示されます。

\begin{figure}

{\centering \includegraphics[width=1\linewidth]{images/PatientLevelPrediction/shiny/shinyModelTable} 

}

\caption{モデル詳細テーブル}(\#fig:shinyModelTable)
\end{figure}

\BeginKnitrBlock{rmdimportant}
予測モデルは因果モデルではなく、予測変数を原因と誤解しないようにしてください。図 \@ref(fig:shinyModelTable) のいずれかの変数を変更することでアウトカムのリスクが影響を受ける保証はありません。

\EndKnitrBlock{rmdimportant}

## 患者レベル予測機能の追加

### ジャーナル論文の生成

自動的にワードドキュメントを生成する機能を追加しました。このドキュメントはジャーナルペーパーの草稿として利用でき、多くの生成された研究の詳細とアウトカムを含みます。外部検証を行った場合、そのアウトカムも追加することができます。また、ターゲット集団の多くの共変量に関するデータを含む「Table 1」を任意で追加することもできます。この機能を実行することでジャーナルペーパーの草稿を作成できます：


``` r
 createPlpJournalDocument(plpResult = <your plp results>,
             plpValidation = <your validation results>,
             plpData = <your plp data>,
             targetName = "<target population>",
             outcomeName = "<outcome>",
             table1 = F,
             connectionDetails = NULL,
             includeTrain = FALSE,
             includeTest = TRUE,
             includePredictionPicture = TRUE,
             includeAttritionPlot = TRUE,
             outputLocation = "<your location>")
```

詳細は関数のヘルプページを参照してください。

## まとめ

\BeginKnitrBlock{rmdsummary}
- 患者レベルの予測は、過去のデータを使用して将来の出来事を予測するモデルを開発することを目的としています。

- モデル開発に最適な機械学習アルゴリズムの選択は経験的な問題であり、具体的な問題とデータに依存します。

- PatientLevelPredictionパッケージは、OMOP CDMに保存されたデータを使用した予測モデルの開発と検証のためのベストプラクティスを実装しています。

- モデルとその性能指標の発信はインタラクティブなダッシュボードを通じて行います。

- OHDSIの予測フレームワークは、臨床採用の前提条件である予測モデルの大規模な外部検証を可能にします。


\EndKnitrBlock{rmdsummary}

## 演習

#### 前提条件 {.unnumbered}

これらの演習では、セクション \@ref(installR) で説明されているように、R、R-Studio、およびJavaがインストールされていることを前提としています。また、[SqlRender](https://ohdsi.github.io/SqlRender/)、[DatabaseConnector](https://ohdsi.github.io/DatabaseConnector/)、[Eunomia](https://ohdsi.github.io/Eunomia/)および[PatientLevelPrediction](https://ohdsi.github.io/PatientLevelPrediction/)パッケージも必要です。これらは以下のコマンドでインストールできます：


``` r
install.packages(c("SqlRender", "DatabaseConnector", "remotes"))
remotes::install_github("ohdsi/Eunomia", ref = "v1.0.0")
remotes::install_github("ohdsi/PatientLevelPrediction")
```

Eunomiaパッケージは、CDM内のシミュレートされたデータセットを提供し、これをローカルのRセッション内で実行できます。接続詳細は以下のコマンドで取得できます：


``` r
connectionDetails <- Eunomia::getEunomiaConnectionDetails()
```

CDMデータベースのスキーマは「main」です。これらの演習ではいくつかのコホートも使用します。Eunomiaパッケージの`createCohorts`関数は、これをCOHORTテーブルに作成します：


``` r
Eunomia::createCohorts(connectionDetails)
```

#### 問題定義 {.unnumbered}

> 初めてNSAIDs（非ステロイド性抗炎症剤）を使用し始めた患者において、次の年に消化管（GI）出血を発症する患者を予測します。

NSAIDの新規ユーザーコホートのCOHORT_DEFINITION_IDは4です。GI出血コホートのCOHORT_DEFINITION_IDは3です。

::: {.exercise #exercisePlp1}
PatientLevelPrediction Rパッケージを使用して、予測に使用する共変量を定義し、CDMからPLPデータを抽出します。PLPデータの概要を作成します。

:::

::: {.exercise #exercisePlp2}
最終的なターゲット集団を定義するための設計の選択肢を再考し、これを`createStudyPopulation`関数を使用して明確にします。これらの選択肢がターゲット集団の最終的なサイズに与える影響はどのようになるでしょうか？

:::

::: {.exercise #exercisePlp3}
LASSOを使用して予測モデルを構築し、Shinyアプリケーションを使用してその性能を評価します。モデルの性能はどの程度ですか？

:::

提案された回答は、付録 \@ref(Plpanswers)で見つけることができます。
