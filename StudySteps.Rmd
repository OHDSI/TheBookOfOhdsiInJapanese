# (PART) OHDSI研究 {.unnumbered}

# --翻訳作業中--　研究の段階 {#StudySteps}

*章の著者: Sara Dempster & Martijn Schuemie*

ここでは、OHDSIツールを用いた観察研究の設計と実施のための一般的なステップ・バイ・ステップのガイドを提供することを目的としています。研究プロセスの各段階を分けて説明し、ステップを一般的に説明するだけでなく、主要な研究タイプ（1）特徴分析、（2）集団レベルの推定（PLE）、および（3）患者レベルの予測（PLP）に関連する特定の側面について議論します。これにより、OHDSIの本の前の章で説明した多くの要素を初心者にも理解しやすい形式で統合します。同時に、この章は他の章のより深い内容を必要に応じて追求するオプションを提供する、実践的な高レベルの説明を求める読者にとって単独で使えるものにもなっています。最後に、いくつかの重要な例を通じて説明を行います。

さらに、OHDSIコミュニティが推奨する観察研究のガイドラインとベストプラクティスを要約します。ここで議論するいくつかの原則は、他の多くの観察研究用ガイドラインで見つかるベストプラクティスと共有される一般的なものですが、他の推奨プロセスはOHDSIフレームワークに特有のものです。したがって、OHDSIツールスタックによって実現されるOHDSI固有のアプローチを強調します。

この章全体で、読者がOHDSIツール、RおよびSQLのインフラストラクチャを利用できることを前提としているため、このインフラストラクチャの設定に関する事項については議論しません（ガイダンスについては、章\@ref(OhdsiAnalyticsTools)および\@ref(SqlAndR)を参照）。また、読者が主に自分のサイトでOMOP CDMデータベースを使用して研究を実行することに関心を持っていることを前提としています（OMOP ETLについては章\@ref(ExtractTransformLoad)を参照）。しかし、一旦研究パッケージが以下で議論されるように準備されると、それが原則として他のサイトで配布され実行される可能性があることを強調します。OHDSIネットワーク研究の実行に特有の追加の考慮事項（組織的および技術的な詳細を含む）は、章\@ref(NetworkResearch)で詳細に議論されています。

## 一般的なベストプラクティスガイドライン

### 観察研究の定義

観察研究とは、特定の患者の治療に介入する試みを行わず、単に患者を観察する研究のことを指します。観察データは、登録研究のように特定の目的のために収集されることもありますが、多くの場合、これらのデータは特定の研究質問とは無関係の目的のために収集されます。後者のデータの一般的な例としては、電子健康記録（EHR）や行政請求データがあります。観察研究は、データの二次利用と呼ばれることがよくあります。観察研究を行う際の基本的な指針の一つは、研究質問を明確にし、研究を実行する前にアプローチを完全に特定することです。この点において、観察研究は臨床試験と何ら変わりはありません。臨床試験では、特定の質問、通常は治療介入の有効性や安全性に関する質問に答えるために患者が募集され、時間をかけてフォローアップされます。観察研究で使用される分析方法は、臨床試験で使用される方法と異なる点が多々あります。特に、PLE（Population-Level Estimation）観察研究ではランダム化が欠如しているため、因果推論を引き出す目的であれば交絡を制御するアプローチが必要です（詳細については、OHDSIがサポートする研究デザインとPLEの方法について議論している章 \@ref(PopulationLevelEstimation) と \@ref(MethodValidity) を参照してください）。

### 研究デザインの事前仕様

観察研究のデザインとパラメータの事前仕様は、望ましい結果を得るために無意識または意識的にアプローチを進化させてしまうこと、しばしばp-ハッキングと呼ばれる行為を避けるために重要です。データの二次利用では、EHRや請求データのように、無限の可能性を感じさせるため、完全に研究の詳細を事前に特定しない誘惑が大きくなります。このため、既存データの容易な利用可能性にもかかわらず、厳格な科学的探求の構造を課すことが重要です。この事前仕様の原則は、最終的に臨床実践や規制上の決定に情報を提供する可能性があるPLP（Patient-Level Prediction）やPLEにおいて特に重要です。純粋に探索的な理由で行われる記述研究であっても、詳細な計画を持つことが望ましいです。でなければ、進化する研究デザインと分析プロセスの文書化、説明、再現が困難になります。

### プロトコル

\index{プロトコル}

観察研究計画は、研究を実行する前に作成されたプロトコルの形式で文書化されるべきです。最低限でも、プロトコルは主要な研究質問、アプローチ、質問に答えるために使用される指標を説明します。研究集団は、他の人々によって完全に再現できる程度の詳細で説明されるべきです。さらに、すべての方法や統計手法、および指標、表、グラフのような予想結果の形式も説明されるべきです。 プロトコルには、研究の実現可能性や統計的検出力を評価するための事前分析のセットが含まれることがよくあります。さらに、プロトコルには感度分析と呼ばれる主要な研究質問のバリエーションの説明が含まれることがあります。感度分析は、研究デザインの選択が全体的な研究結果に与える潜在的な影響を評価するために設計されており、可能な限り事前に説明されるべきです。時には、予期しない問題が発生し、プロトコルが完成した後にプロトコルの修正が必要になることがあります。この場合、プロトコル自体に変更点と変更理由を文書化することが重要です。特にPLEやPLPの場合、完成した研究プロトコルは、clinicaltrials.govやOHDSIのstudyProtocolsサンドボックスのような独立したプラットフォームに記録され、そのバージョンと修正がタイムスタンプ付きで独立して追跡できるようにするのが理想的です。また、多くの場合、あなたの所属機関やデータソースの所有者が研究の実行前にあなたのプロトコルを確認および承認する機会を求めるでしょう。

### 標準化された分析

OHDSIのユニークな利点は、ツールが観察研究で繰り返し問われる主要な質問のいくつかを認識することによって、計画、文書化、および報告をサポートする方法です（章 \@ref(WhereToBegin), \@ref(DataAnalyticsUseCases), \@ref(Characterization), \@ref(PopulationLevelEstimation), \@ref(PatientLevelPrediction) を参照）。このことによって、プロトコルの開発と研究の実施プロセスを自動化する側面が繰り返されます。 ツールの多くは、多くのケースで遭遇するユースケースをカバーするための、いくつかの研究デザインや指標をパラメータ化するように設計されています。例えば、研究者が研究集団といくつかの追加パラメータを特定し、複数の薬剤や結果を比較調査する場合、多数の比較研究を実施できます。研究者の質問が一般的なテンプレートに適合する場合、多くの基本的な研究集団の説明やプロトコルに必要なその他のパラメータの生成を自動化する方法が存在します。歴史的に、これらのアプローチは、観察研究デザインが薬物と有害事象の間の既知の因果関係をどれだけ再現できるかを評価するOMOP実験から動機付けられ、さまざまな研究デザインとパラメータを反復的に検討しました。

OHDSIのアプローチは、共通のフレームワークとツール内でこれらのステップを比較的簡単に実行できるようにすることで、プロトコル内での実現可能性と研究診断の包括をサポートしています（詳細は以下の「実現可能性」セクション \@ref(Feasibility) を参照してください）。

### 研究パッケージ

\index{研究パッケージ}

もう一つの標準化されたテンプレートとデザインの動機は、研究者がプロトコルの形式で研究を完全に詳細に記述していると考えていても、研究を実行するための完全なコンピュータコードを生成するために実際に十分に指定されていない要素が存在する可能性があるからです。このため、OHDSIフレームワークによって可能になる基本原則の一つは、コンピュータコードの形式で文書化された完全に追跡可能で再現可能なプロセスを生成すること、しばしば「研究パッケージ」と呼ばれるものです。OHDSIのベストプラクティスは、このような研究パッケージをgit環境に記録することです。この研究パッケージには、すべてのパラメータとコードベースのバージョンスタンプが含まれます。前述したように、観察研究はしばしば公衆衛生の決定や政策に影響を与える可能性のある質問をしています。このため、どのような発見に基づいて行動する前に、理想的には異なる研究者によって複数の設定で再現されるべきです。このような目標を達成する唯一の方法は、研究を完全に再現するために必要なすべての詳細が明確に文書化され、推測や誤解に頼らないことです。このベストプラクティスをサポートするために、OHDSIツールは、書面でのドキュメント形式のプロトコルからコンピュータまたは機械読み取り可能な研究パッケージへの変換を支援するように設計されています。このフレームワークのトレードオフの一つは、すべてのユースケースまたはカスタマイズされた分析が既存のOHDSIツールで簡単に対応できるわけではないことです。しかし、コミュニティが成長し進化するにつれ、もっと多くのユースケースに対応するための機能が追加されています。コミュニティの一員は、斬新なユースケースによって駆動される新しい機能の提案を行うことができます。

### CDMに基づくデータ

OHDSIの研究は、観察データベースがOMOP共通データモデル（CDM）に変換されることを前提としています。すべてのOHDSIツールとダウンストリーム分析ステップは、データ表現がCDMの仕様に準拠していることを前提としています（詳細は「共通データモデル」章 \@ref(CommonDataModel) を参照）。したがって、特定のデータソースに対してETLプロセス（抽出、変換、ロード）が十分に文書化されていることも重要です。このプロセスは、サイト間でデータベース間にアーティファクトや違いを生じさせる可能性があるからです。OMOP CDMの目的は、サイト固有のデータ表現の削減に向けて進むことですが、これはまだ完全ではなく、コミュニティが改善を目指す挑戦的な領域の一つです。したがって、研究を実行する際には、あなたのサイトやネットワーク研究を実行する際には外部サイトのソースデータに詳しい個人と協力することが重要です。

CDMに加えて、OMOP標準化語彙システム（章 \@ref(StandardizedVocabularies)）も、異なるデータソース間での相互運用性を得るためにOHDSIフレームワークを使用する上で重要な要素です。標준化語彙は、それぞれの語彙ドメイン内の標準概念を定義します。すべてのソース語彙システムはこれらの標準概念にマッピングされます。このようにして、薬剤、診断、手順のために異なるソース語彙システムを使用する2つの異なるデータベースが、CDMに変換されると比較可能になります。OMOP語彙はまた、特定のコホート定義に適切なコードを特定するのに役立つ階層も含んでいます。このため、ETLの恩恵を最大限に受け、OMOP CDMにデータベースを変換し、OMOP語彙を使用した下流のクエリを実行するために、語彙のマッピングを実装し、OMOP標準化語彙のコードを使用することが推奨されるベストプラクティスです。

## 詳細な研究手順

### 質問を定義する

最初のステップは、研究の関心を精密な質問に変換し、観察研究で取り扱える状態にすることです。例えば、臨床糖尿病研究者として、2型糖尿病 (T2DM) 患者に対するケアの質を調査したいとします。この大きな目標を、Chapter \@ref(DataAnalyticsUseCases) で最初に説明した3種類の質問のいずれかに該当する、より具体的な質問に分解することができます。

特性研究では、「与えられた医療環境で、軽度の2型糖尿病と重度の2型糖尿病に対する処方慣行が現在推奨されている内容に一致しているか？」と問うことができます。この質問は、特定の治療の効果に関する因果関係を問うものではなく、単に既存の臨床指針と比較してデータベース内の処方慣行を特徴付けるものです。

また、T2DM治療の処方指針が心疾患とT2DMの両方診断された特定のサブセット患者に最適かどうかについて懐疑的かもしれません。このような研究は、PLE調査として翻訳できます。具体的には、心不全などの心血管イベントを防ぐために、2つの異なるT2DM薬クラスの比較効果に関する質問をすることができます。異なる薬を服用しているが、どちらのコホートもT2DMと心疾患の診断を受けている患者の2つのコホートで、心不全の入院リスクの相対的なリスクを検討する研究を設計することが考えられます。

あるいは、軽度のT2DMから重度のT2DMに進行する患者を予測するモデルを開発したいと思うかもしれません。これはPLP質問としてフレーム化でき、重度のT2DMに進行するリスクが高い患者をより厳密なケアのために識別するのに役立ちます。

実用的な観点から、研究質問を定義することは、質問に答えるために必要なアプローチがOHDSIツールセット内の利用可能な機能に一致しているかどうかを評価することも必要です（現在のツールで対応可能な質問種別に関する詳細な議論はChapter \@ref(DataAnalyticsUseCases) を参照してください）。もちろん、自分の分析ツールを設計したり、現在利用可能なものを修正して他の質問に答えることも可能です。

### データの可用性と質を確認する

特定の研究質問にコミットする前に、データの質をレビューし（Chapter \@ref(DataQuality) を参照）、特定の観察医療データベースの性質、フィールドの詳細、およびデータカバーのケア設定について十分に理解することをお勧めします。これにより、特定のデータベースで研究質問が実現不可能になる可能性のある問題を迅速に特定できます。以下では、いくつかの一般的な問題を指摘します。

上記の軽度のT2DMが重度のT2DMに進行する予測モデルの開発例に戻りましょう。理想的には、T2DMの重度は患者の血糖値を過去3ヶ月平均で反映する検査測定であるグリコヘモグロビン（HbA1c）レベルを調べることで評価されるかもしれません。これらの値はすべての患者に利用できる場合とそうでない場合があります。すべてまたは一部の患者に利用できない場合、T2DMの重症度に関する他の臨床基準を特定し、代わりに使用できるかどうかを検討する必要があります。あるいは、HbA1c値が一部の患者にしか利用できない場合、その部分集団に焦点を当てることで、研究に不要なバイアスが発生するかどうかも評価する必要があります。欠損データの問題についての追加の議論はChapter \@ref(DataAnalyticsUseCases) を参照してください。

もう一つの一般的な問題は、特定のケア設定に関する情報の欠如です。前述のPLE例では、推奨される結果は心不全のための入院でした。与えられたデータベースに入院情報が全くない場合、異なる結果を考慮して、異なるT2DM治療アプローチの比較有効性を評価する必要があります。他のデータベースでは、外来患者の診断データが利用できない場合もあり、その場合、コホートの設計を考慮する必要があります。

### 研究対象集団

研究対象集団または集団を定義することは、どの研究においても基本的なステップです。観察研究では、研究対象集団を代表する個人のグループは、多くの場合、コホートと呼ばれます。コホートへの選択に必要な患者の特性は、その時点の臨床質問に関連する研究対象集団によって決まります。例えば、T2DMの診断コードを含む医療記録を持つ18歳以上の患者という単純なコホートは、ANDロジックで接続された2つの基準を持つことになります。コホート定義には、複数の複雑な入れ子のブールロジックや特定の調査期間、患者のベースライン期間の必要な長さなど、さらに多くの基準が含まれていることがよくあります。

精緻化されたコホート定義セットは、適適な科学論文のレビューと、特定のデータベースで適切な患者グループを特定する際の課題を理解している臨床および技術的な専門家のアドバイスを必要とします。観察データを扱う際には、これらのデータが患者の医療履歴の完全な図を提供していないことを念頭に置いておくことが重要です。それはむしろ、人間のエラーや情報の記録の際に導入されたバイアスの影響を受けやすい一時的なスナップショットです。特定の患者は、観察期間と呼ばれる限られた期間のみフォローされる場合があります。特定のデータベースやケア設定、および研究対象である病気や治療に応じて、臨床研究者は最も一般的なエラーの原因を回避するための提案を行うことができます。簡単な例を挙げると、T2DM患者を特定する際の一般的な問題は、T1DM患者が誤ってT2DMの診断コードを持っていることです。T1DM患者は基本的に異なるグループであるため、T2DM患者を対象とする研究にT1DM患者のグループが誤って含まれると、結果が狂う可能性があります。強固なT2DMコホートの定義を持つためには、T1DM患者が誤って含まれることを避けるために、糖尿病治療としてインスリンのみが処方された患者を除外することが必要です。しかし、T2DMの診断コードを持つすべての患者の特性に興味がある場合、この場合、誤ってコーディングされたT1DM患者を排除しようとする追加の基準を適用することは適切ではないかもしれません。

Once the definition of a study population or populations is described, the OHDSI tool ATLAS is a good starting point to create the relevant cohorts. ATLAS and the cohort generation process are described in detail in Chapters \@ref(OhdsiAnalyticsTools) and \@ref(Cohorts). Briefly, ATLAS provides a user interface (UI) to define and generate cohorts with detailed inclusion criteria. Once cohorts are defined in ATLAS, a user can directly export their detailed definitions in a human-readable format for incorporation in a protocol. If for some reason an ATLAS instance is not connected to an observational health database, ATLAS can still be used to create a cohort definition and directly export the underlying SQL code for incorporation into a study package to be run separately on a SQL database server. Directly using ATLAS is recommended when possible because ATLAS provides some advantages above and beyond the creation of SQL code for the cohort definition (see below). Finally, there may be some rare situations where a cohort definition can not be implemented with the ATLAS UI and requires manual custom SQL code.

The ATLAS UI enables defining cohorts based on numerous selection criteria. Criteria for cohort entry and exit as well as baseline criteria can be defined on the basis of any domains of the OMOP CDM such as conditions, drugs, procedures, etc. where standard codes must be specified for each domain. In addition, logical filters on the basis of these domains, as well as time-based filters to define study periods, and baseline timeframes can be defined within ATLAS. ATLAS can be particularly helpful when selecting codes for each criteria. ATLAS incorporates a vocabulary-browsing feature which can be used to build sets of codes required for your cohort definitions. This feature relies solely on the OMOP standard vocabularies and has options to include all descendants in the vocabulary hierarchy (see Chapter \@ref(StandardizedVocabularies)). Note therefore that this feature requires that all codes have been appropriately mapped to standard codes during the ETL process (see Chapter \@ref(ExtractTransformLoad)). If the best codesets to use in your inclusion criteria are not clear, this may be a place where some exploratory analysis may be warranted in cohort definitions. Alternatively a more formal sensitivity analysis could be considered to account for different possible definitions of a cohort using different codesets.

Assuming that ATLAS is configured appropriately to connect to a database, SQL queries to generate the defined cohorts can be run directly within ATLAS. ATLAS will automatically assign each cohort a unique id which can also be used to directly reference the cohort in the backend database for future use. The cohort may be directly used within ATLAS to run an incidence rate study or it may be pointed to directly in the backend database by code in a PLE or PLP study package. For a given cohort, ATLAS saves only the patient ids, index dates and cohort exit dates of the individuals in the cohorts. This information is sufficient to derive all the other attributes or covariates that may be needed for the patients such as patient’s baseline covariates for a characterization, PLE or PLP study.

When a cohort is created, summary characteristics of the patient demographics and frequencies of the most frequent drugs and conditions observed can be created and viewed by default directly within ATLAS.

In reality, most studies require specifying multiple cohorts or multiple sets of cohorts which are then compared in various ways to gain new clinical insights. For PLE and PLP, the OHDSI tools provide a structured framework to define these multiple cohorts. For example, in a PLE comparative effectiveness study, you will typically define at least 3 cohorts, a target cohort, a comparator and an outcome cohort (see Chapter \@ref(PopulationLevelEstimation)). In addition, to run a full PLE comparative effectiveness study, you will also need a number of cohorts with negative control outcomes and positive control outcomes. The OHDSI toolset provides ways to help speed and in some cases automate the generation of these negative and positive control cohorts as discussed in detail in Chapter \@ref(MethodValidity).

As a final note, defining cohorts for a study may benefit from ongoing work in the OHDSI community to define a library of robust and validated phenotypes where a phenotype is essentially an exportable cohort definition. If any of these existing cohort definitions are appropriate for your study, the exact definitions can be obtained by import of a json file into your ATLAS instance.

### Feasibility and Diagnostics {#Feasibility}

\index{study feasibility!single study} \index{study diagnostics}

Once cohorts are defined and generated, a more formal process to examine study feasibility in available data sources can be undertaken and the findings summarized in the finalized protocol. An evaluation of study feasibility can encompass a number of exploratory and sometimes iterative activities. We describe a few common aspects here.

A primary activity at this stage will be to thoroughly review the distributions of characteristics within your cohorts to ensure that the cohort you generated is consistent with the desired clinical characteristics and flag any unexpected characteristics. Returning to our T2DM example above, by characterizing this simple T2DM cohort by reviewing the frequencies of all other diagnoses received, one may be able to flag the issue of also capturing patients with T1DM or other unanticipated issues. It is good practice to build such a step of initially characterizing any new cohort into the study protocol as a quality check of clinical validity of the cohort definition. In terms of implementation, the easiest way to perform a first pass at this will be to examine the cohort demographics and top drugs and conditions that can be generated by default when a cohort is created in ATLAS. If the option to create the cohorts directly within ATLAS is not available, manual SQL or use of the R feature extraction package can be used to characterize a cohort. In practice, in a larger PLE study or PLP study, these steps can be built into the study package with feature extraction steps.

Another common and important step to assess feasibility for a PLE or PLP is an assessment of cohort sizes and the counts of outcomes in the target and comparator cohorts. The incidence rate feature of ATLAS can be used to find these counts which can be used to perform power calculations as described elsewhere.

Another option which is highly recommended for a PLE study is to complete the propensity score (PS) matching steps and relevant diagnostics to ensure that there is sufficient overlap between the populations in the target and comparator groups. These steps are described in detail in Chapter \@ref(PopulationLevelEstimation). In addition, using these final matched cohorts, the statistical power can then be calculated.

In some cases, work in the OHDSI community examines the statistical power only after a study is run by reporting a minimal detectable relative risk (MDRR) given the available sample sizes. This approach may be more useful when running high throughput, automated studies across a lot of databases and sites. In this scenario, a study's power in any given database is perhaps better explored after the all analyses have been performed rather than pre-filtering.

### Finalize Protocol and Study Package

Once the legwork for all the previous steps has been completed, a final protocol should be assembled that includes detailed cohort definitions and study design information ideally exported from ATLAS. In Appendix \@ref(ProtocolTemplate), we provide a sample table of contents for a full protocol for a PLE study. This can also be found on the OHDSI github. We provide this sample as a comprehensive guide and checklist, but note some sections may or may not be relevant for your study.

As shown in Figure \@ref(fig:studyProcess), assembling the final study protocol in human-readable form should be performed in parallel with preparing all the machine-readable study code that is incorporated into the final study package. These latter steps are referred to as study implementation in the diagram below. This will include export of the finalized study package from ATLAS and/or development of any custom code that may be required.

The completed study package can then be used to execute only the preliminary diagnostics steps which in turn can be described in the protocol. For example, in the case of a new user cohort PLE study to examine comparative effectiveness of two treatments, the preliminary execution of study diagnostics steps will require cohort creation, propensity score creation, and matching to confirm that the target and comparator populations have sufficient overlap for the study to be feasible. Once this is determined, power calculations can be performed with the matched target and comparator cohorts intersected with the outcome cohort to obtain outcome counts and the results of these calculations can be described in the protocol. On the basis of these diagnostics results, a decision can then be made whether or not to move forward with executing the final outcome model. In the context of a characterization or a PLP study, there may be similar steps that need to be completed at this stage, although we don’t attempt to outline all scenarios here.

Importantly, we recommend at this stage to have your finalized protocol reviewed by clinical collaborators and stakeholders.

```{r studyProcess, fig.cap='Diagram of the study process.',echo=FALSE, out.width='90%', fig.align='center'}
knitr::include_graphics("images/StudySteps/studyProcess.png")
```

### Execute Study

Once all prior steps have been completed, study execution should ideally be straightforward. Of course, the code or process should be reviewed for fidelity to the methods and parameters outlined in the protocol. It may also be necessary to test and debug a study package to ensure it runs appropriately in your environment.

### Interpretation and Write-Up

In a well-defined study where sample sizes are sufficient and data quality is reasonable, the interpretation of results will often be straightforward. Similarly, because most of the work of creating a final report other than writing up the final results is done in the planning and creation of the protocol, the final write-up of a report or manuscript for publication will often be straightforward as well.

There are, however, some common situations where interpretation becomes more challenging and should be approached with caution.

1.  Sample sizes are borderline for significance and confidence intervals become large
2.  Specific for PLE: p-value calibration with negative controls may reveal substantial bias
3.  Unanticipated data quality issues come to light during the process of running the study

For any given study, it will be up to the discretion of the study authors to report on any concerns above and temper their interpretation of study results accordingly. As with the protocol development process, we also recommend that the study findings and interpretations be reviewed by clinical experts and stakeholders prior to releasing a final report or submitting a manuscript for publication.

## まとめ

```{block2, type='rmdsummary'}
- 研究は明確に定義された質問を検討すべきです。
- データの質、完全性、および関連性の事前チェックを適切に行う。
- 可能であれば、プロトコルの開発過程にデータベースの専門家を含めることを推奨。
- 提案された研究を事前にプロトコルで文書化する。
- 書面によるプロトコルと並行して研究パッケージコードを生成し、最終研究の実行前に実行可能性および診断を行い、それを説明する。
- 研究は実行前に登録され、必要に応じて承認されるべきです。
- 最終的な報告書または原稿は、臨床の専門家やその他の関係者によるレビューを受けるべきです。


```
